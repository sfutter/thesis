---
title: "neural network model"
author: "Steven Futter"
date: "5/30/2017"
output: html_document
---

# MODEL 3: ANN using H2O - multinomial classification
http://h2o-release.s3.amazonaws.com/h2o/rel-tverberg/5/index.html
Useful tutorial: https://github.com/h2oa i/h2o-tutorials/tree/master/tutorials/deeplearning

ONLY NEED THIS ON FIRST RUN THROUGH
```{r}
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }

# Next, we download packages that H2O depends on.
if (! ("methods" %in% rownames(installed.packages()))) { install.packages("methods") }
if (! ("statmod" %in% rownames(installed.packages()))) { install.packages("statmod") }
if (! ("stats" %in% rownames(installed.packages()))) { install.packages("stats") }
if (! ("graphics" %in% rownames(installed.packages()))) { install.packages("graphics") }
if (! ("RCurl" %in% rownames(installed.packages()))) { install.packages("RCurl") }
if (! ("jsonlite" %in% rownames(installed.packages()))) { install.packages("jsonlite") }
if (! ("tools" %in% rownames(installed.packages()))) { install.packages("tools") }
if (! ("utils" %in% rownames(installed.packages()))) { install.packages("utils") }

# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-tverberg/5/R")))
library(h2o)
localH2O = h2o.init(nthreads=-1)
```


######################################################
#### STEP 1: 1-HOUR AHEAD PREDICTIONS    #############
#### TRAIN MODEL and CREATE TRAIN, TEST, #############
#### VALIDATION PREDICTIONS then EXPORT  #############
#### OUTPUT for ALL VARIABLES            #############
######################################################

```{r}
library(dplyr)
library(lubridate)
codePath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","R CODE")
source(file.path(codePath,"thesis_data_preparation_part3_take2.R"))

# This loop through is needed for prediction hours after 9AM .. i.e. 10am to 4pm
response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2')    

# best.model.vars = ['NO2','Year','Time','lag.1.NO2', 'lag.2.NO2', 'X5amTo8amSlope.NOX.IMP', 'TimeHoursNum', 'RHUM']

createDataFrameNO2 = function(df,predictor){
  dfNew = df %>% select(NO2, Year, Time, lag.1.NO2, lag.2.NO2, X5amTo8amSlope.NOX.IMP, TimeHoursNum, RHUM)     
  return(dfNew)
}



#for (i in 1:1){
for ( i in 1:length(response)){
  
modelPath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","MODELS") 
inPath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

responseCol = response[i]                 # set first column to the predicted response
df = createDataFrameNO2(df, responseCol)     # lags 1-3, current hour meteo, slopes for prior 8am.

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# remove year now that validation set has been removed
df.train.time = as.h2o(df.train.temp$Time)
df.test.time  = as.h2o(df.test.temp$Time)
df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year, -Time)
df.test  = df.test.temp  %>% select(-Year, -Time)
df.vali  = df.vali.temp  %>% select(-Year, -Time)


# Train ANN then calculate train / test MSE
########################################################################
# MODEL 1: ANN that uses half as many hidden nodes as variable inputs. 
########################################################################
#library(h2o) # ONLY NEED ON FIRST RUN THROUGH
#h2o.init()   # ONLY NEED ON FIRST RUN THROUGH
df.train.hex <- as.h2o(df.train)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# Rule of thumb that the hidden nodes should be half as many columns (to begin with) -- later we will try other rules here for the number of hidden nodes
colcount    = dim(df.train.hex)[2]
hiddencount = 10  # need to run the neural network with half as many hidden nodes as input nodes
modelID = paste0(response[i],'.dl')          # creates unique model id for each variable!
df.train.dl <- h2o.deeplearning(x = 2:colcount, y = 1, training_frame = df.train.hex, validation_frame= df.test.hex, hidden=c(hiddencount), 
                                distribution= "AUTO", variable_importances = TRUE, model_id = modelID, reproducible = TRUE, seed = 1234, nfolds=10)
# summary(df.train.dl)

# Save the model
model_path <- h2o.saveModel(object=df.train.dl, path=modelPath, force=TRUE)
# print(model_path)
# /tmp/mymodel/DeepLearning_model_R_1441838096933

# make a prediction here for train, test, validation set response
predictions.train <- h2o.predict(df.train.dl, df.train.hex)
predictions.test  <- h2o.predict(df.train.dl, df.test.hex)
predictions.vali  <- h2o.predict(df.train.dl, df.vali.hex)



# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTrain = paste0('greenwich_eltham_',response[i],'_ann_train_1_hr_ahead_final.csv')   # TWO HOURS AHEAD, THREE HOURS, ETC... WILL BE THE NAMES OF THE NEW FILES
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead_final.csv')
 
# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTrain = as.data.frame(h2o.cbind(df.train.time, predictions.train,df.train.hex))
colnames(dfExportTrain)[1] = 'Time'
#dfExportTrain = dfExportTrain %>% filter(TimeHoursNum == '9')
#dfExportTrain$TimeKey1 = as.POSIXct(dfExportTrain$Time) + hours(1)
#dfExportTrain$TimeKey2 = as.POSIXct(dfExportTrain$Time) + hours(2)
#dfExportTrain$TimeKey3 = as.POSIXct(dfExportTrain$Time) + hours(3)
#dfExportTrain$TimeKey4 = as.POSIXct(dfExportTrain$Time) + hours(4)
#dfExportTrain$TimeKey5 = as.POSIXct(dfExportTrain$Time) + hours(5)
#keepIdx = which(names(dfExportTrain) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
#dfExportTrain = dfExportTrain[,keepIdx]
write.csv(dfExportTrain, file.path(outfilePath,filenameTrain))   # to here: we have exported a training file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(df.test.time, predictions.test,df.test.hex))
colnames(dfExportTest)[1] = 'Time'
#dfExportTest = dfExportTest %>% filter(TimeHoursNum == '9')
#dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
#dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
#dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
#dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
#dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
#keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
#dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(df.vali.time, predictions.vali,df.vali.hex))
colnames(dfExportVali)[1] = 'Time'
#dfExportVali = dfExportVali %>% filter(TimeHoursNum == '9')
#dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
#dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
#dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
#dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
#dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
#keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
#dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars

}
```





######################################################
#### STEP 2: 8-HOUR AHEAD PREDICTIONS    #############
#### TRAIN MODEL and CREATE TRAIN, TEST, #############
#### VALIDATION PREDICTIONS then EXPORT  #############
#### OUTPUT for ALL VARIABLES            #############
######################################################

# create 9AM
```{r}
library(dplyr)
library(lubridate)
codePath = file.path("~/Dropbox","NU","THESIS","R CODE")
source(file.path(codePath,"thesis_data_preparation_part3_take2.R"))

# This loop through is needed for prediction hours after 9AM .. i.e. 10am to 4pm
response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2')    

# best.model.vars = ['NO2','Year','Time','lag.1.NO2', 'lag.2.NO2', 'X5amTo8amSlope.NOX.IMP', 'TimeHoursNum', 'RHUM']
createDataFrameNO2 = function(df,predictor){
  dfNew = df %>% select(NO2, Year, Time, lag.1.NO2, lag.2.NO2, X5amTo8amSlope.NOX.IMP, TimeHoursNum, RHUM)     
  return(dfNew)
}

#for (i in 1:1){
for ( i in 1:length(response)){
  
modelPath = file.path("~/Dropbox","NU","THESIS","MODELS") 
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

responseCol = response[i]                       # set first column to the predicted response
df = createDataFrameNO2(df, responseCol)        # lags 1-3, current hour meteo, slopes for prior 8am.

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)   # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)   # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# remove year now that validation set has been removed
df.train.time = as.h2o(df.train.temp$Time)
df.test.time  = as.h2o(df.test.temp$Time)
df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year, -Time)
df.test  = df.test.temp  %>% select(-Year, -Time)
df.vali  = df.vali.temp  %>% select(-Year, -Time)


# Train ANN then calculate train / test MSE
########################################################################
# MODEL 1: ANN that uses half as many hidden nodes as variable inputs. 
########################################################################
#library(h2o) # ONLY NEED ON FIRST RUN THROUGH
#h2o.init()   # ONLY NEED ON FIRST RUN THROUGH
df.train.hex <- as.h2o(df.train)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# Rule of thumb that the hidden nodes should be half as many columns (to begin with) -- later we will try other rules here for the number of hidden nodes
colcount    = dim(df.train.hex)[2]
hiddencount = 10  # need to run the neural network with half as many hidden nodes as input nodes
modelID = paste0(response[i],'.dl')          # creates unique model id for each variable!
df.train.dl <- h2o.deeplearning(x = 2:colcount, y = 1, training_frame = df.train.hex, validation_frame= df.test.hex, hidden=c(hiddencount), 
                                distribution= "AUTO", variable_importances = TRUE, model_id = modelID, reproducible = TRUE, seed = 1234, nfolds=10)
# summary(df.train.dl)

# Save the model
model_path <- h2o.saveModel(object=df.train.dl, path=modelPath, force=TRUE)
# print(model_path)
# /tmp/mymodel/DeepLearning_model_R_1441838096933

# make a prediction here for train, test, validation set response
predictions.train <- h2o.predict(df.train.dl, df.train.hex)
predictions.test  <- h2o.predict(df.train.dl, df.test.hex)
predictions.vali  <- h2o.predict(df.train.dl, df.vali.hex)



# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTrain = paste0('greenwich_eltham_',response[i],'_ann_train_1_hr_ahead_final.csv')   # TWO HOURS AHEAD, THREE HOURS, ETC... WILL BE THE NAMES OF THE NEW FILES
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead_final.csv')
 
# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTrain = as.data.frame(h2o.cbind(df.train.time, predictions.train,df.train.hex))
colnames(dfExportTrain)[1] = 'Time'
dfExportTrain = dfExportTrain %>% filter(TimeHoursNum == '9')
dfExportTrain$TimeKey1 = as.POSIXct(dfExportTrain$Time) + hours(1)
dfExportTrain$TimeKey2 = as.POSIXct(dfExportTrain$Time) + hours(2)
dfExportTrain$TimeKey3 = as.POSIXct(dfExportTrain$Time) + hours(3)
dfExportTrain$TimeKey4 = as.POSIXct(dfExportTrain$Time) + hours(4)
dfExportTrain$TimeKey5 = as.POSIXct(dfExportTrain$Time) + hours(5)
keepIdx = which(names(dfExportTrain) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTrain = dfExportTrain[,keepIdx]
write.csv(dfExportTrain, file.path(outfilePath,filenameTrain))   # to here: we have exported a training file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(df.test.time, predictions.test,df.test.hex))
colnames(dfExportTest)[1] = 'Time'
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '9')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(df.vali.time, predictions.vali,df.vali.hex))
colnames(dfExportVali)[1] = 'Time'
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '9')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars

}
```


# THE 9AM PREDICTION HAS JUST BEEN MADE FOR ALL VARIABLES

# STEP 2 - UPDATE TEST AND VALIDATION FILE WITH "1-HOUR" PREDICTION
# PREDICTED 9AM (TAKEN AT 8AM) BECOMES THE T-1 HOUR LAG FOR THE 10AM PREDICTION. 
# USE TIMEKEY1 FROM THE 9AM PREDICTION IN _ann_test_1_hr_ahead.csv FILE AS THE KEY for the 10AM. At 10am the t-1 lag is 9AM.
# note: IN THE 9AM FILE THE TIMEKEY1 REPRESENTS 10AM KEY, TIMEKEY2 REPRESENTS 11AM KEY... ETC. 

# 10 AM PREDICTION NEXT - jul 15

```{r}
# A. RECREATE PRE-PROCESSED TEST RAW DATA PROVIDED -- for TEST and VALIDATION SAMPLES --- REPLACING ACTUAL-LAG-1 WITH PREDICTED-LAG-1
#    LAYOUT NEEDS TO BE EXACTLY THE SAME AS BEFORE.

# This loop through is needed for prediction hours after 9AM .. i.e. 10am to 4pm
response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') #, 'BP', 'RAIN', 'RHUM', 'SOLR', 'TEMP', 'WDIR','WSPD')


########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# # remove year now that validation set has been removed
# df.train.time = as.h2o(df.train.temp$Time)
# df.test.time  = as.h2o(df.test.temp$Time)
# df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)


# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"




# Next: update DF test and DF vali with lag 1s 
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar) 

lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar) 

#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_2_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_2_hr_ahead_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex)) #df.test.time, predictions.test,df.test.hex))
#colnames(dfExportTest)[1] = 'Time'
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '10')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex)) #df.vali.time, predictions.vali,df.vali.hex))
# colnames(dfExportVali)[1] = 'Time'
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '10')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars

}

```



# 10 PREDICTIONS HAVE JUST BEEN MADE


# lets repeat for 11AM PREDICTION NEXT - jul 15

```{r}
# A. RECREATE PRE-PROCESSED TEST RAW DATA PROVIDED -- for TEST and VALIDATION SAMPLES --- REPLACING ACTUAL-LAG-1 WITH PREDICTED-LAG-1
#    LAYOUT NEEDS TO BE EXACTLY THE SAME AS BEFORE.

response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') #, 'BP', 'RAIN', 'RHUM', 'SOLR', 'TEMP', 'WDIR','WSPD')


########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# # remove year now that validation set has been removed
# df.train.time = as.h2o(df.train.temp$Time)
# df.test.time  = as.h2o(df.test.temp$Time)
# df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)



# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"




# Next: update DF test and DF vali with lag 1s 

# STEP 1 TEST: add 1-hour lag from 10am prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1) 

# STEP 2 TEST: add 2-hour lag from 9AM prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2) 

# STEP 1 VALI: add 1-hour lag from 10am prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1) 

# STEP 2 VALI: add 2-hour lag from 9am prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2) 


#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_3_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_3_hr_ahead_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex))
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '11')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex))
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '11')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))   

}

```





# 11AM PREDICTIONS HAVE JUST BEEN MADE


# lets repeat for 12AM PREDICTION NEXT - jul 15

```{r}
# A. RECREATE PRE-PROCESSED TEST RAW DATA PROVIDED -- for TEST and VALIDATION SAMPLES --- REPLACING ACTUAL-LAG-1 WITH PREDICTED-LAG-1
#    LAYOUT NEEDS TO BE EXACTLY THE SAME AS BEFORE.

response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') #, 'BP', 'RAIN', 'RHUM', 'SOLR', 'TEMP', 'WDIR','WSPD')


########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# # remove year now that validation set has been removed
# df.train.time = as.h2o(df.train.temp$Time)
# df.test.time  = as.h2o(df.test.temp$Time)
# df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)



# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"




# Next: update DF test and DF vali with lag 1s 

# STEP 1 TEST: add 1-hour lag from 11am prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1) 

# STEP 2 TEST: add 2-hour lag from 10AM prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2) 

# STEP 3 TEST: add 3-hour lag from 9AM prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.test = updateDF_tMinus3Lags(df.test, lagPredictor, filenameInputVar3) 


# STEP 1 VALI: add 1-hour lag from 11am prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1) 

# STEP 2 VALI: add 2-hour lag from 10am prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2) 

# STEP 3 VALI: add 3-hour lag from 9am prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.vali = updateDF_tMinus3Lags(df.vali, lagPredictor, filenameInputVar3) 


#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_4_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_4_hr_ahead_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex))
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '12')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex))
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '12')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))   

}

```


# 12AM PREDICTIONS HAVE JUST BEEN MADE


# lets repeat for 1PM PREDICTION NEXT - jul 15

```{r}
# A. RECREATE PRE-PROCESSED TEST RAW DATA PROVIDED -- for TEST and VALIDATION SAMPLES --- REPLACING ACTUAL-LAG-1 WITH PREDICTED-LAG-1
#    LAYOUT NEEDS TO BE EXACTLY THE SAME AS BEFORE.

response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') #, 'BP', 'RAIN', 'RHUM', 'SOLR', 'TEMP', 'WDIR','WSPD')

########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# # remove year now that validation set has been removed
# df.train.time = as.h2o(df.train.temp$Time)
# df.test.time  = as.h2o(df.test.temp$Time)
# df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)



# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"




# Next: update DF test and DF vali with lag 1s 

# STEP 1 TEST: add 1-hour lag from 12am prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_4_hr_ahead_final.csv')                          # 4 hour ahead is 12AM prediction taken at 8AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1) 

# STEP 2 TEST: add 2-hour lag from 11AM prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2) 

# STEP 3 TEST: add 3-hour lag from 10AM prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_test_2_hr_ahead_final.csv')                          # 2 hour ahead is 9AM prediction taken at 8AM
df.test = updateDF_tMinus3Lags(df.test, lagPredictor, filenameInputVar3) 

# STEP 4 TEST: add 4-hour lag from 9AM prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.test = updateDF_tMinus4Lags(df.test, lagPredictor, filenameInputVar4) 


# STEP 1 VALI: add 1-hour lag from 12am prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_4_hr_ahead_final.csv')                          # 4 hour ahead is 12AM prediction taken at 8AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1) 

# STEP 2 VALI: add 2-hour lag from 11am prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2) 

# STEP 3 VALI: add 3-hour lag from 10am prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_vali_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.vali = updateDF_tMinus3Lags(df.vali, lagPredictor, filenameInputVar3) 

# STEP 4 VALI: add 4-hour lag from 9am prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.vali = updateDF_tMinus4Lags(df.vali, lagPredictor, filenameInputVar4) 


#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex))
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '13')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex))
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '13')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))   

}

```



# TO THIS POINT WE HAVE MADE THE 1PM PREDICTION

# lets repeat for 2PM PREDICTION NEXT - jul 15

```{r}
# A. RECREATE PRE-PROCESSED TEST RAW DATA PROVIDED -- for TEST and VALIDATION SAMPLES --- REPLACING ACTUAL-LAG-1 WITH PREDICTED-LAG-1
#    LAYOUT NEEDS TO BE EXACTLY THE SAME AS BEFORE.

response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') #, 'BP', 'RAIN', 'RHUM', 'SOLR', 'TEMP', 'WDIR','WSPD')




########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# remove year now that validation set has been removed
df.train.time = as.h2o(df.train.temp$Time)
df.test.time  = as.h2o(df.test.temp$Time)
df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)


# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"




# Next: update DF test and DF vali with lag 1s 

# STEP 1 TEST: add 1-hour lag from 1PM prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_final.csv')                          # 5 hour ahead is 1PM prediction taken at 8AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1) 

# STEP 2 TEST: add 2-hour lag from 12AM prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_4_hr_ahead_final.csv')                          # 4 hour ahead is 12AM prediction taken at 8AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2) 

# STEP 3 TEST: add 3-hour lag from 11AM prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_test_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.test = updateDF_tMinus3Lags(df.test, lagPredictor, filenameInputVar3) 

# STEP 4 TEST: add 4-hour lag from 10AM prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_test_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.test = updateDF_tMinus4Lags(df.test, lagPredictor, filenameInputVar4) 

# STEP 5 TEST: add 5-hour lag from 9AM prediction
filenameInputVar5  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.test = updateDF_tMinus5Lags(df.test, lagPredictor, filenameInputVar5) 



# STEP 1 VALI: add 1-hour lag from 1Pm prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_final.csv')                          # 5 hour ahead is 1PM prediction taken at 8AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1) 

# STEP 2 VALI: add 2-hour lag from 12am prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_4_hr_ahead_final.csv')                          # 4 hour ahead is 12AM prediction taken at 8AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2) 

# STEP 3 VALI: add 3-hour lag from 11am prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_vali_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.vali = updateDF_tMinus3Lags(df.vali, lagPredictor, filenameInputVar3) 

# STEP 4 VALI: add 4-hour lag from 10am prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_vali_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.vali = updateDF_tMinus4Lags(df.vali, lagPredictor, filenameInputVar4) 

# STEP 5 VALI: add 5-hour lag from 9am prediction
filenameInputVar5  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead_final.csv')                          # 1 hour ahead is 9AM prediction taken at 8AM
df.vali = updateDF_tMinus5Lags(df.vali, lagPredictor, filenameInputVar5) 



#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_6_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_6_hr_ahead_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex))
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '14')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex))
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '14')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))   

}

```

# JUST CREATED THE 2PM PREDICTION
# lets repeat for 3PM PREDICTION NEXT - jul 15

```{r}
# A. RECREATE PRE-PROCESSED TEST RAW DATA PROVIDED -- for TEST and VALIDATION SAMPLES --- REPLACING ACTUAL-LAG-1 WITH PREDICTED-LAG-1
#    LAYOUT NEEDS TO BE EXACTLY THE SAME AS BEFORE.

response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') #, 'BP', 'RAIN', 'RHUM', 'SOLR', 'TEMP', 'WDIR','WSPD')



########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# # remove year now that validation set has been removed
# df.train.time = as.h2o(df.train.temp$Time)
# df.test.time  = as.h2o(df.test.temp$Time)
# df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)



# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"




# Next: update DF test and DF vali with lag 1s 

# STEP 1 TEST: add 1-hour lag from 2PM prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_6_hr_ahead_final.csv')                          # 6 hour ahead is 2PM prediction taken at 8AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1) 

# STEP 2 TEST: add 2-hour lag from 1PM prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_final.csv')                          # 5 hour ahead is 1PM prediction taken at 8AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2) 

# STEP 3 TEST: add 3-hour lag from 12AM prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_test_4_hr_ahead_final.csv')                          # 4 hour ahead is 12AM prediction taken at 8AM
df.test = updateDF_tMinus3Lags(df.test, lagPredictor, filenameInputVar3) 

# STEP 4 TEST: add 4-hour lag from 11AM prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_test_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.test = updateDF_tMinus4Lags(df.test, lagPredictor, filenameInputVar4) 

# STEP 5 TEST: add 5-hour lag from 10AM prediction
filenameInputVar5  = paste0('greenwich_eltham_',response[i],'_ann_test_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.test = updateDF_tMinus5Lags(df.test, lagPredictor, filenameInputVar5) 



# STEP 1 VALI: add 1-hour lag from 2Pm prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_6_hr_ahead_final.csv')                          # 6 hour ahead is 2PM prediction taken at 8AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1) 

# STEP 2 VALI: add 2-hour lag from 1pm prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_final.csv')                          # 5 hour ahead is 1PM prediction taken at 8AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2) 

# STEP 3 VALI: add 3-hour lag from 12am prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_vali_4_hr_ahead_final.csv')                          # 5 hour ahead is 12AM prediction taken at 8AM
df.vali = updateDF_tMinus3Lags(df.vali, lagPredictor, filenameInputVar3) 

# STEP 4 VALI: add 4-hour lag from 11am prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_vali_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.vali = updateDF_tMinus4Lags(df.vali, lagPredictor, filenameInputVar4) 

# STEP 5 VALI: add 5-hour lag from 10am prediction
filenameInputVar5  = paste0('greenwich_eltham_',response[i],'_ann_vali_2_hr_ahead_final.csv')                          # 2 hour ahead is 10AM prediction taken at 8AM
df.vali = updateDF_tMinus5Lags(df.vali, lagPredictor, filenameInputVar5) 



#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_7_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_7_hr_ahead_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex))
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '15')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex))
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '15')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))   

}

```


# JUST CREATED THE 3PM PREDICTION
# lets repeat for 4PM PREDICTION NEXT - jul 15

```{r}
# A. RECREATE PRE-PROCESSED TEST RAW DATA PROVIDED -- for TEST and VALIDATION SAMPLES --- REPLACING ACTUAL-LAG-1 WITH PREDICTED-LAG-1
#    LAYOUT NEEDS TO BE EXACTLY THE SAME AS BEFORE.

response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') #, 'BP', 'RAIN', 'RHUM', 'SOLR', 'TEMP', 'WDIR','WSPD')



########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

# # remove year now that validation set has been removed
# df.train.time = as.h2o(df.train.temp$Time)
# df.test.time  = as.h2o(df.test.temp$Time)
# df.vali.time  = as.h2o(df.vali.temp$Time)

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)



# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"




# Next: update DF test and DF vali with lag 1s 

# STEP 1 TEST: add 1-hour lag from 3PM prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_7_hr_ahead_final.csv')                          # 7 hour ahead is 3PM prediction taken at 8AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1) 

# STEP 2 TEST: add 2-hour lag from 2PM prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_6_hr_ahead_final.csv')                          # 6 hour ahead is 2PM prediction taken at 8AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2) 

# STEP 3 TEST: add 3-hour lag from 1PM prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_final.csv')                          # 5 hour ahead is 1PM prediction taken at 8AM
df.test = updateDF_tMinus3Lags(df.test, lagPredictor, filenameInputVar3) 

# STEP 4 TEST: add 4-hour lag from 12AM prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_test_4_hr_ahead_final.csv')                          # 4 hour ahead is 12AM prediction taken at 8AM
df.test = updateDF_tMinus4Lags(df.test, lagPredictor, filenameInputVar4) 

# STEP 5 TEST: add 5-hour lag from 11AM prediction
filenameInputVar5  = paste0('greenwich_eltham_',response[i],'_ann_test_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.test = updateDF_tMinus5Lags(df.test, lagPredictor, filenameInputVar5) 



# STEP 1 VALI: add 1-hour lag from 3PM prediction
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_7_hr_ahead_final.csv')                          # 7 hour ahead is 3PM prediction taken at 8AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1) 

# STEP 2 VALI: add 2-hour lag from 2pm prediction
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_6_hr_ahead_final.csv')                          # 6 hour ahead is 2PM prediction taken at 8AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2) 

# STEP 3 VALI: add 3-hour lag from 1PM prediction
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_final.csv')                          # 5 hour ahead is 1PM prediction taken at 8AM
df.vali = updateDF_tMinus3Lags(df.vali, lagPredictor, filenameInputVar3) 

# STEP 4 VALI: add 4-hour lag from 12am prediction
filenameInputVar4  = paste0('greenwich_eltham_',response[i],'_ann_vali_4_hr_ahead_final.csv')                          # 4 hour ahead is 12AM prediction taken at 8AM
df.vali = updateDF_tMinus4Lags(df.vali, lagPredictor, filenameInputVar4) 

# STEP 5 VALI: add 5-hour lag from 11am prediction
filenameInputVar5  = paste0('greenwich_eltham_',response[i],'_ann_vali_3_hr_ahead_final.csv')                          # 3 hour ahead is 11AM prediction taken at 8AM
df.vali = updateDF_tMinus5Lags(df.vali, lagPredictor, filenameInputVar5) 



#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_8_hr_ahead_final.csv')
filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_8_hr_ahead_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex))
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '16')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex))
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '16')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))   

}

```



##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################   REPEAT EXERCISE ABOVE BUT WITH RESET AT LUNCH  ##############################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################
##########################################################################################################################################################################

# LET'S CARRY OUT THE SAME WAY AS ABOVE BUT RESET LAGGED 
# PREDICT 1-4 HOURS AHEAD FOR 9, 10, 11, 12, THEN RESET AND PREDICT 1-4 HOURS AHEAD FOR 1,2,3,4PM
# files created above for 1-4 hours ahead are still valid here. 
# begin with prediction of 1PM (5 hours ahead), but rename the output file so that its 5_hours_ahead_1HR_predict.csv


# NEXT IS 1PM PREDICTION ***** RESET ***** THEREFORE USE ACTUAL RECORDED DATA FOR LAGGED VALUES!

```{r}
response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') 

########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)


# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"


#############################################
#######      RESETING AT 1PM            #####
####### NO PREDICTION NEEDED FOR LAGS   #####
#############################################

#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath  = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_reset_13_final.csv')
filenameVali = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_reset_13_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex)) #df.test.time, predictions.test,df.test.hex))
#colnames(dfExportTest)[1] = 'Time'
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '13')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex)) #df.vali.time, predictions.vali,df.vali.hex))
# colnames(dfExportVali)[1] = 'Time'
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '13')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars

}

```


# 1PM PREDICTION HAS JUST BEEN MADE 



# NEXT IS THE 2PM PREDICTION - use 1PM predicted output as input for lag.1 vars

```{r}
response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') 

########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)


# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"


# Next: 1-HOUR LAG IS 1PM PREDICTION
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_reset_13_final.csv')                          # 5 hr ahead is 1PM prediction taken at 12AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1)

# repeat for vali set
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_reset_13_final.csv')                          # 5 hr ahead is 1PM prediction taken at 12AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1)

#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath  = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest = paste0('greenwich_eltham_',response[i],'_ann_test_6_hr_ahead_reset_13_final.csv')
filenameVali = paste0('greenwich_eltham_',response[i],'_ann_vali_6_hr_ahead_reset_13_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex)) #df.test.time, predictions.test,df.test.hex))
#colnames(dfExportTest)[1] = 'Time'
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '14')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex)) #df.vali.time, predictions.vali,df.vali.hex))
# colnames(dfExportVali)[1] = 'Time'
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '14')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars

}

```


# 2PM PREDICTION HAS JUST BEEN MADE

# NEXT PREDICT THE 3PM - use 1-hr lag from 2pm prediction, and 2-hr lag from 1pm prediction

```{r}
response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') 

########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)


# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"



# use 1-hr lag from 2pm prediction, 
# and 2-hr lag from 1pm prediction

# Next: 1-HOUR LAG IS 2PM PREDICTION
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_6_hr_ahead_reset_13_final.csv')                          # 6 hr ahead is 2PM prediction taken at 12AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1)

filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_6_hr_ahead_reset_13_final.csv')                          # 6 hr ahead is 2PM prediction taken at 12AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1)

# 2-HOUR LAG IS 1PM PREDICTION
lagPredictor      = paste0('lag.2.',response[i])
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_reset_13_final.csv')                          # 5 hr ahead is 1PM prediction taken at 12AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2)

filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_reset_13_final.csv')                          # 5 hr ahead is 1PM prediction taken at 12AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2)


#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath  = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest = paste0('greenwich_eltham_',response[i],'_ann_test_7_hr_ahead_reset_13_final.csv')
filenameVali = paste0('greenwich_eltham_',response[i],'_ann_vali_7_hr_ahead_reset_13_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex)) #df.test.time, predictions.test,df.test.hex))
#colnames(dfExportTest)[1] = 'Time'
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '15')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex)) #df.vali.time, predictions.vali,df.vali.hex))
# colnames(dfExportVali)[1] = 'Time'
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '15')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars

}

```

# 3PM PREDICTED ABOVE. 

# next PREDICT 4PM - use 1-hour from 3PM prediction, 2-hour lag from 2PM prediction, and the 3-lag from 3PM prediction. 
```{r}
response    = c('NO2') #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') 

########################################
# LOAD SAVED MODEL From Step 1 ABOVE #
########################################
for (i in 1:length(response)) {   # 1 is NO2. 
  model_path  <- paste0("/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/",response[i],".dl") 
  saved_model <- h2o.loadModel(model_path)    # "/Users/stevenfutter/Dropbox/NU/THESIS/R CODE/~/Dropbox/NU/THESIS/MODELS/no2.dl"


# Load test data frame
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

# Set response column and recreate test/vali data frames
responseCol = response[i]                 # set first column to the predicted response
df = createDataFrame(df, responseCol)

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf

# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

# rename the df to df.train, df.test, and df.vali respectively
df.train.temp = df[train,]
df.test.temp  = df[-train,]
df.vali.temp = validationDf

df.train = df.train.temp %>% select(-Year) #, -Time)
df.test  = df.test.temp  %>% select(-Year) #, -Time)
df.vali  = df.vali.temp  %>% select(-Year) #, -Time)


# names(df.test)   # same as df.vali
#   [1] "NO2"                     "Time"                    "Year"                    "Month"                   "TimeHoursNum"            "lag.1.NO"               
#   [7] "lag.2.NO"                "lag.3.NO"                "lag.4.NO"                "lag.5.NO"                "lag.1.NO2"               "lag.2.NO2"              
#  [13] "lag.3.NO2"               "lag.4.NO2"               "lag.5.NO2"               "lag.1.NOX"               "lag.2.NOX"               "lag.3.NOX"              
#  [19] "lag.4.NOX"               "lag.5.NOX"               "lag.1.O3"                "lag.2.O3"                "lag.3.O3"                "lag.4.O3"               
#  [25] "lag.5.O3"                "lag.1.PM10"              "lag.2.PM10"              "lag.3.PM10"              "lag.4.PM10"              "lag.5.PM10"             
#  [31] "lag.1.PM2.5"             "lag.2.PM2.5"             "lag.3.PM2.5"             "lag.4.PM2.5"             "lag.5.PM2.5"             "lag.1.SO2"              
#  [37] "lag.2.SO2"               "lag.3.SO2"               "lag.4.SO2"               "lag.5.SO2"               "lag.1.BP"                "lag.2.BP"               
#  [43] "lag.3.BP"                "lag.4.BP"                "lag.5.BP"                "lag.1.RAIN"              "lag.2.RAIN"              "lag.3.RAIN"             
#  [49] "lag.4.RAIN"              "lag.5.RAIN"              "lag.1.RHUM"              "lag.2.RHUM"              "lag.3.RHUM"              "lag.4.RHUM"             
#  [55] "lag.5.RHUM"              "lag.1.SOLR"              "lag.2.SOLR"              "lag.3.SOLR"              "lag.4.SOLR"              "lag.5.SOLR"             
#  [61] "lag.1.TEMP"              "lag.2.TEMP"              "lag.3.TEMP"              "lag.4.TEMP"              "lag.5.TEMP"              "lag.1.WDIR"             
#  [67] "lag.2.WDIR"              "lag.3.WDIR"              "lag.4.WDIR"              "lag.5.WDIR"              "lag.1.WSPD"              "lag.2.WSPD"             
#  [73] "lag.3.WSPD"              "lag.4.WSPD"              "lag.5.WSPD"              "X5amTo8amSlope.NO2.IMP"  "X5amTo8amSlope.NO.IMP"   "X5amTo8amSlope.NOX.IMP" 
#  [79] "X5amTo8amSlope.O3.IMP"   "X5amTo8amSlope.PM10.IMP" "X5amTo8amSlope.SO2.IMP"  "X5amTo8amSlope.BP.IMP"   "X5amTo8amSlope.RAIN.IMP" "X5amTo8amSlope.RHUM.IMP"
#  [85] "X5amTo8amSlope.SOLR.IMP" "X5amTo8amSlope.TEMP.IMP" "X5amTo8amSlope.WDIR.IMP" "X5amTo8amSlope.WSPD.IMP" "X2amTo5amSlope.NO2.IMP"  "X2amTo5amSlope.NO.IMP"  
#  [91] "X2amTo5amSlope.NOX.IMP"  "X2amTo5amSlope.O3.IMP"   "X2amTo5amSlope.PM10.IMP" "X2amTo5amSlope.SO2.IMP"  "X2amTo5amSlope.BP.IMP"   "X2amTo5amSlope.RAIN.IMP"
#  [97] "X2amTo5amSlope.RHUM.IMP" "X2amTo5amSlope.SOLR.IMP" "X2amTo5amSlope.TEMP.IMP" "X2amTo5amSlope.WDIR.IMP" "X2amTo5amSlope.WSPD.IMP"



# use 1-hr lag from 2pm prediction, 
# and 2-hr lag from 1pm prediction

# Next: 1-HOUR LAG IS 3PM PREDICTION
lagPredictor      = paste0('lag.1.',response[i])
filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_test_7_hr_ahead_reset_13_final.csv')                          # 7 hr ahead is 3PM prediction taken at 12AM
df.test = updateDF_tMinus1Lags(df.test, lagPredictor, filenameInputVar1)

filenameInputVar1  = paste0('greenwich_eltham_',response[i],'_ann_vali_7_hr_ahead_reset_13_final.csv')                          # 7 hr ahead is 2PM prediction taken at 12AM
df.vali = updateDF_tMinus1Lags(df.vali, lagPredictor, filenameInputVar1)


# 2-HOUR LAG IS 2PM PREDICTION
lagPredictor      = paste0('lag.2.',response[i])
filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_test_6_hr_ahead_reset_13_final.csv')                          # 6 hr ahead is 2PM prediction taken at 12AM
df.test = updateDF_tMinus2Lags(df.test, lagPredictor, filenameInputVar2)

filenameInputVar2  = paste0('greenwich_eltham_',response[i],'_ann_vali_6_hr_ahead_reset_13_final.csv')                          # 6 hr ahead is 2PM prediction taken at 12AM
df.vali = updateDF_tMinus2Lags(df.vali, lagPredictor, filenameInputVar2)


# 3-HOUR LAG IS 1PM PREDICTION
lagPredictor      = paste0('lag.3.',response[i])
filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_test_5_hr_ahead_reset_13_final.csv')                          # 5 hr ahead is 2PM prediction taken at 12AM
df.test = updateDF_tMinus3Lags(df.test, lagPredictor, filenameInputVar3)

filenameInputVar3  = paste0('greenwich_eltham_',response[i],'_ann_vali_5_hr_ahead_reset_13_final.csv')                          # 5 hr ahead is 2PM prediction taken at 12AM
df.vali = updateDF_tMinus3Lags(df.vali, lagPredictor, filenameInputVar3)



#### RUN 10AM PREDICTION #### - factorize Time first so it can be put into h2o data.frame
df.test$Time = as.factor(df.test$Time)
df.vali$Time = as.factor(df.vali$Time)
df.test.hex  <- as.h2o(df.test)
df.vali.hex  <- as.h2o(df.vali)

# make a prediction here for train, test, validation set response
predictions.test  <- h2o.predict(saved_model, df.test.hex)
predictions.vali  <- h2o.predict(saved_model, df.vali.hex)

# Export the data prediction for the testing and validation data sets
outfilePath  = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS")
filenameTest = paste0('greenwich_eltham_',response[i],'_ann_test_8_hr_ahead_reset_13_final.csv')
filenameVali = paste0('greenwich_eltham_',response[i],'_ann_vali_8_hr_ahead_reset_13_final.csv')

# EXPORT THE TEST DATA SET PREDICTIONS
dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex)) #df.test.time, predictions.test,df.test.hex))
#colnames(dfExportTest)[1] = 'Time'
dfExportTest = dfExportTest %>% filter(TimeHoursNum == '16')
dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1)
dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2)
dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3)
dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4)
dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5)
keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportTest = dfExportTest[,keepIdx]
write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars

# EXPORT THE VALIDATION DATA SET PREDICTIONS
dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex)) #df.vali.time, predictions.vali,df.vali.hex))
# colnames(dfExportVali)[1] = 'Time'
dfExportVali = dfExportVali %>% filter(TimeHoursNum == '16')
dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1)
dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2)
dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3)
dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4)
dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5)
keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5"))
dfExportVali = dfExportVali[,keepIdx]
write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars

}

```
