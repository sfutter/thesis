---
title: "Thesis Data Preparation"
author: "Steven Futter"
date: "3/30/2017"
output: html_document
---


# 1a. Get all raw data from LondonAir: Greenwich Eltham else Bexley Belvedere West & Bexley Erith
```{r}
library(dplyr)

inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","LONDON_AIR") # Home path
ge.no = read.csv(file.path(inPath,"greenwich_eltham_no_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.no2 = read.csv(file.path(inPath,"greenwich_eltham_no2_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.nox = read.csv(file.path(inPath,"greenwich_eltham_nox_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.o3 = read.csv(file.path(inPath,"greenwich_eltham_o3_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.pm2.5 = read.csv(file.path(inPath,"greenwich_eltham_pm2.5_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.pm10 = read.csv(file.path(inPath,"greenwich_eltham_pm10_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.so2 = read.csv(file.path(inPath,"greenwich_eltham_so2_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.bp = read.csv(file.path(inPath,"greenwich_eltham_bp_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
be.bp = read.csv(file.path(inPath,"greenwich_eltham_bexley_erith_bp_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.rain = read.csv(file.path(inPath,"greenwich_eltham_rain_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
bbw.rain = read.csv(file.path(inPath,"greenwich_eltham_bexley_belvedere_west_rain_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.rhum = read.csv(file.path(inPath,"greenwich_eltham_rhum_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
bbw.rhum = read.csv(file.path(inPath,"greenwich_eltham_bexley_belvedere_west_rhum_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.solr = read.csv(file.path(inPath,"greenwich_eltham_solr_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
drg.solr = read.csv(file.path(inPath,"greenwich_eltham_dagenham_rush_green_solr_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.temp = read.csv(file.path(inPath,"greenwich_eltham_temp_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
bbw.temp = read.csv(file.path(inPath,"greenwich_eltham_bexley_belvedere_west_temp_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.wdir = read.csv(file.path(inPath,"greenwich_eltham_wdir_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))
ge.wspd = read.csv(file.path(inPath,"greenwich_eltham_wspd_2008_2016.csv"),na.strings=c("NA"," "),colClasses = c("factor", "factor", "factor", "numeric", "character", "factor"))

dim(ge.no)    # all are 78912     6
dim(ge.no2)
dim(ge.nox)
dim(ge.o3)
dim(bbw.rain)
dim(drg.solr)

``` 


# 1b. Combine the different site variables into one data frame using the date timestamp as the join key. Note that the date timestampe 'ReadingDateTime' covers all days from jan 1 2008 to dec 31 2016. 
```{r}
df1  = full_join(ge.no,ge.no2,       by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.nox,         by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.o3,          by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.pm10,        by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.pm2.5,       by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.so2,         by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.bp,          by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,be.bp,          by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.rain,        by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,bbw.rain,       by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.rhum,        by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,bbw.rhum,       by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.solr,        by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,drg.solr,       by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.temp,        by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,bbw.temp,       by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.wdir,        by = c("ReadingDateTime" = "ReadingDateTime"))
df1  = full_join(df1,ge.wspd,        by = c("ReadingDateTime" = "ReadingDateTime"))

dim(df1)  # 78912    96
```


#1c. Use nearby station data when values for GE are missing (explain distances and reasoning here: XXX)
```{r}
names(df1)
# for full join
keepCols = which(names(df1) %in% c('Site.x', 'ReadingDateTime',
                                   'Value.x','Value.y',
                                   'Value.x.x','Value.y.y',
                                   'Value.x.x.x','Value.y.y.y',
                                   'Value.x.x.x.x','Value.y.y.y.y',
                                   'Value.x.x.x.x.x','Value.y.y.y.y.y',
                                   'Value.x.x.x.x.x','Value.y.y.y.y.y',
                                   'Value.x.x.x.x.x.x','Value.y.y.y.y.y.y',
                                   'Value.x.x.x.x.x.x.x','Value.y.y.y.y.y.y.y', 
                                   'Value.x.x.x.x.x.x.x.x', 'Value.y.y.y.y.y.y.y.y',
                                   'Value.x.x.x.x.x.x.x.x.x', 'Value.y.y.y.y.y.y.y.y.y',
                                   'Value'))


df2 = df1[,keepCols]

colnames(df2) = c("Site","Time","NO","NO2","NOX","O3","PM10","PM2.5","SO2","BP.GE","BP.BE","RAIN.GE","RAIN.BBW","RHUM.GE","RHUM.BBW","SOLR.GE","SOLR.DRG","TEMP.GE","TEMP.BBW","WDIR","WSPD")  #BBW = bexley belvedere west

# IMPUTE values for temp, rain, rhum, bp, solr
df2 = mutate(df2, TEMP.IMP = ifelse(is.na(TEMP.GE),TEMP.BBW, TEMP.GE))
df2 = mutate(df2, RAIN.IMP = RAIN.BBW)
df2 = mutate(df2, RHUM.IMP = ifelse(is.na(RHUM.GE),RHUM.BBW, RHUM.GE))
df2 = mutate(df2, BP.IMP   = ifelse(is.na(BP.GE),BP.BE, BP.GE))
df2 = mutate(df2, SOLR.IMP = ifelse(is.na(SOLR.GE),SOLR.DRG, SOLR.GE))

outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED")
write.csv(df2, file.path(outfilePath,'greenwich_eltham_with_replace_bexley_rain_temp_rhum_hourly_B.csv'))

dim(df2)
```


# 1d. Create Date column since Time field provided includes two different formats of dates. 
```{r}
(x <- strptime(df2$Time, format="%d/%m/%Y %H:%M"))          # Strip time from date
df2$TimeHours = format(x,"%H:%M")

df2$TimeHoursNum = sapply(strsplit(df2$TimeHours,":"),       # function to convert character time hours:sec into numeric
  function(x) {
    x <- as.numeric(x)
    x[1]+x[2]/60
    }
)

# add some time, date columns -- note: something going on with date here. Some are 2-digit Year, other 4.
df2$TimeAlt1 = as.Date(df2$Time, format="%d/%m/%y %H:%M")       # Convert the Time variable to date format
df2$TimeAlt2 = as.Date(df2$Time, format="%d/%m/%Y %H:%M")       # Convert the Time variable to date format
df2 = mutate(df2, Date = ifelse(is.na(as.character(TimeAlt1)),as.character(TimeAlt2), as.character(TimeAlt1)))
df2$Date = as.Date(df2$Date, '%Y-%m-%d')

# new data frame with Date2 and TimeHoursNum2
min(df2$Date) # 2008-01-01
max(df2$Date) # 2016-12-31 


###### THE ALL HOURS AND DATES DATA FRAME CREATED BELOW IS ACTUALLY NOT NEEDED SINCE THE ORIGINAL DATA SET COMES WITH ALL HOURS 
###### IN THE YEAR ALREADY. RATHER THAN CBIND THE TWO DATA FRAMES TOGETHER I DECIDE TO GO WITHOUT. THIS CONFIRMS HOWEVER THAT THE
###### ORIGINAL DATA SET DOES INCLUDE ALL HOURS OF THE YEAR BETWEEN 2008 AND 2016. 
# create vector of ALL DATES & HOURS between jan 1 2008 and dec 31 2016. Confirmed that data set provided by LondonAir includes all dates & hours. 
# all.dates = seq(as.Date("2008-01-01"), as.Date("2016-12-31"), by="days")
# all.dates = data.frame(all.dates,'Key')
# all.hours = seq(0,23)
# all.hours = data.frame(all.hours, 'Key')
# all.hours.df = inner_join(all.dates,all.hours,by = c("X.Key." = "X.Key."))
# all.hours.df = all.hours.df %>% select (all.dates,  all.hours)
# dim(all.hours.df)  # 78912 is all hours over the time period min-max above. This matches the number of rows in the data frame above.

```


# 2a. Check summary of Missing Values - all variables
```{r}
df3 = df2
names(df3)
df.temp = df3 %>% select(NO:WSPD)

# part 1 - all vars
countMissing = sapply(df.temp, function(x) sum(is.na(x)))
percentMissing = round(apply(df.temp, 2, function(col)sum(is.na(col))/length(col)),2)

df.temp.missing = data.frame(countMissing, percentMissing)
df.temp.missing = df.temp.missing[order(-percentMissing),]  # with ordering on desc percentMissing 
df.temp.missing
```

# 2b. Check summary of missing values for the imputed BP, RAIN, RHUM, TEMP, and SOLR variables. 
```{r}
# Let's now see the values for Imputed RAIN, RHUM, BP, SOLR, and TEMP
names(df3)
df.temp = df3 %>% select(TEMP.IMP:SOLR.IMP)

countMissing   = sapply(df.temp, function(x) sum(is.na(x)))
percentMissing = round(apply(df.temp, 2, function(col)sum(is.na(col))/length(col)),2)

df.temp.missing = data.frame(countMissing, percentMissing)
df.temp.missing = df.temp.missing[order(-percentMissing),] # with ordering on desc percentMissing
df.temp.missing

```


# 3a. Rename imputed node site variables to main variable names
```{r}
# To this point we ahve imputed the values for BP, RAIN, RHUM, TEMP, and SOLR from the nearby sites: Bexley Erith, Bexley Belvedere West, and Dagenham Rush Green. 
names(df2)
df3 = df2 %>% select(Site,Time, NO,NO2,NOX,O3,PM10,PM2.5,SO2,BP.IMP,RAIN.IMP,RHUM.IMP,SOLR.IMP,TEMP.IMP,WDIR,WSPD, TimeHoursNum,Date)
colnames(df3) = c('Site','Time', 'NO','NO2','NOX','O3','PM10','PM2.5','SO2','BP','RAIN','RHUM','SOLR','TEMP','WDIR','WSPD','TimeHoursNum','Date')
```

# 3b. Update the Time column so that the date time value is present
note that the column has a slight problem in the raw data file -- date is provided in two different formats.
```{r}
require(reshape)
require(tidyr)

df3$Time1 = strptime(df3$Time, format = '%d/%m/%y %H:%M', 'GMT')
df3$Time1 = strftime(df3$Time1, format = '%Y-%m-%d %H:%M')

df3$Time2 = strptime(df3$Time, format = '%d/%m/%Y %H:%M', 'GMT')
df3$Time2 = strftime(df3$Time2, format = '%Y-%m-%d %H:%M')

df3$TimeAdj = ifelse(is.na(df3$Time1), df3$Time2, df3$Time1)

df3 = df3 %>% select(Site, Date, TimeAdj, TimeHoursNum, NO:WSPD)
colnames(df3) = c('Site','Date', 'TimeAdj', 'TimeHoursNum', 'NO','NO2','NOX','O3','PM10','PM2.5','SO2','BP','RAIN','RHUM','SOLR','TEMP','WDIR','WSPD')
df3 <- dplyr::rename(df3, Time = TimeAdj)

```


# 3c. View time-series plot in prep for predicted vs actual review
```{r}

f <- list(
  family = "Courier New, monospace",
  size = 12,
  color = "#7f7f7f"
)
x <- list(
  title = "Hour of Day",
  size=8,
  titlefont = f
)
y <- list(
  title = "Average Hourly NO2",
  titlefont = f
)

# reduce date range before running this plot:
temp = df3 %>% filter(Date > '2016-01-01' & TimeHoursNum > 5 & TimeHoursNum < 17)
temp
p <- plot_ly(temp, x = ~Time, y=~NO2, name = 'NO2', type='scatter', mode='lines+markers') %>%      
  layout(title = "Hourly NO2",
         xaxis = list(title  = "Hour of Day (24 Hour Clock)"),
         yaxis = list (title = "Hourly NO2 Concentration (µg/m3)"))
p

```

# 3b. Create Year, Month, Week, Day variables. 
```{r}
# detach("package:plyr", unload=TRUE) # needed this to ensure that n = n() was working!!
# http://stackoverflow.com/questions/22801153/dplyr-error-in-n-function-should-not-be-called-directly
df4 = df3

df4$Year = as.numeric(format(df4$Date,'%Y'))                # Get Year and Month from date
df4$Month = as.numeric(format(df4$Date,'%m'))
df4$Week = as.numeric(format(df4$Date,'%W'))
df4$Day <- as.factor(weekdays(df4$Date))
df4$MMYYYY <- as.character(format(df4$Date, "%m/%Y"))

df4 = df4 %>% select(Date, Time, MMYYYY, Year, Month, Week, Day, TimeHoursNum,NO:WSPD)
dim(df4) # 78912 x 21
names(df4)
head(df4)
str(df4)
```

# 4a - create a function where you specify number of lags needed and input variable and then loop through data frame to add the lags.  
#      Attempt 1: create 24 hours of lag values per each predictor variable to begin with. 
#      * Create 1-24 hour lagged variables *
```{r}
# function to create new column in data frame with lagged variable
lagColumnAdd = function(df, predictor, lagCount){  
  existColNames = colnames(df)
  dfNew = df
  for ( i in 1:lagCount){
    laggedVar = lag(dfNew[,predictor], i)
    dfNew = cbind(dfNew, laggedVar)
    colnames(dfNew)[length(dfNew)] = paste0('lag.',i,'.',predictor)
  }
  return(dfNew)
}

df5 = lagColumnAdd(df4, 'NO',    5)  # creates lags 1 to 5
df5 = lagColumnAdd(df5, 'NO2',   5)
df5 = lagColumnAdd(df5, 'NOX',   5)
df5 = lagColumnAdd(df5, 'O3',    5)
df5 = lagColumnAdd(df5, 'PM10',  5)
df5 = lagColumnAdd(df5, 'PM2.5', 5)
df5 = lagColumnAdd(df5, 'SO2',   5)
df5 = lagColumnAdd(df5, 'BP',    5)
df5 = lagColumnAdd(df5, 'RAIN',  5)
df5 = lagColumnAdd(df5, 'RHUM',  5)
df5 = lagColumnAdd(df5, 'SOLR',  5)
df5 = lagColumnAdd(df5, 'TEMP',  5)
df5 = lagColumnAdd(df5, 'WDIR',  5)
df5 = lagColumnAdd(df5, 'WSPD',  5)

```

# 4b. use the lagged variable values to calculate the IMPUTED 'IMP' column values. I use lags 1-5 as they have the stronger correlations with the current hour. After 5 hours there doesn't appear to be a strong correlation.
```{r}
# Use lag1 if available, else use lag 2, else lag 3..etc (to 5). See correlation effort in EDA. 
df5 = mutate(df5, NO.IMP      = ifelse(is.na(NO),    ifelse(is.na(lag.1.NO),    ifelse(is.na(lag.2.NO),   ifelse(is.na(lag.3.NO), ifelse(is.na(lag.4.NO), lag.5.NO, lag.4.NO), lag.3.NO),    lag.2.NO) ,    lag.1.NO ),      NO         ))
df5 = mutate(df5, NO2.IMP     = ifelse(is.na(NO2),   ifelse(is.na(lag.1.NO2),   ifelse(is.na(lag.2.NO2),  ifelse(is.na(lag.3.NO2), ifelse(is.na(lag.4.NO2), lag.5.NO2, lag.4.NO2), lag.3.NO2),    lag.2.NO2) ,    lag.1.NO2 ),      NO2 ))
df5 = mutate(df5, NOX.IMP     = ifelse(is.na(NOX),   ifelse(is.na(lag.1.NOX),   ifelse(is.na(lag.2.NOX),  ifelse(is.na(lag.3.NOX), ifelse(is.na(lag.4.NOX), lag.5.NOX, lag.4.NOX), lag.3.NOX),    lag.2.NOX) ,    lag.1.NOX ),      NOX ))
df5 = mutate(df5, O3.IMP      = ifelse(is.na(O3),    ifelse(is.na(lag.1.O3),    ifelse(is.na(lag.2.O3),   ifelse(is.na(lag.3.O3), ifelse(is.na(lag.4.O3), lag.5.O3, lag.4.O3), lag.3.O3),    lag.2.O3) ,    lag.1.O3 ),      O3      ))
df5 = mutate(df5, PM10.IMP= ifelse(is.na(PM10),  ifelse(is.na(lag.1.PM10),  ifelse(is.na(lag.2.PM10), ifelse(is.na(lag.3.PM10), ifelse(is.na(lag.4.PM10), lag.5.PM10, lag.4.PM10), lag.3.PM10),    lag.2.PM10) ,  lag.1.PM10 ), PM10    ))
df5 = mutate(df5, SO2.IMP = ifelse(is.na(SO2),   ifelse(is.na(lag.1.SO2),   ifelse(is.na(lag.2.SO2),  ifelse(is.na(lag.3.SO2), ifelse(is.na(lag.4.SO2), lag.5.SO2, lag.4.SO2), lag.3.SO2),    lag.2.SO2) ,    lag.1.SO2 ),  SO2      ))
df5 = mutate(df5, BP.IMP  = ifelse(is.na(BP),    ifelse(is.na(lag.1.BP),    ifelse(is.na(lag.2.BP),   ifelse(is.na(lag.3.BP), ifelse(is.na(lag.4.BP), lag.5.BP, lag.4.BP), lag.3.BP),    lag.2.BP) ,    lag.1.BP ),      BP      ))
df5 = mutate(df5, RAIN.IMP= ifelse(is.na(RAIN),  ifelse(is.na(lag.1.RAIN),  ifelse(is.na(lag.2.RAIN), ifelse(is.na(lag.3.RAIN), ifelse(is.na(lag.4.RAIN), lag.5.RAIN, lag.4.RAIN), lag.3.RAIN),    lag.2.RAIN) ,    lag.1.RAIN ),      RAIN      ))
df5 = mutate(df5, RHUM.IMP= ifelse(is.na(RHUM),  ifelse(is.na(lag.1.RHUM),  ifelse(is.na(lag.2.RHUM), ifelse(is.na(lag.3.RHUM), ifelse(is.na(lag.4.RHUM), lag.5.RHUM, lag.4.RHUM), lag.3.RHUM),    lag.2.RHUM) ,    lag.1.RHUM ),      RHUM      ))
df5 = mutate(df5, SOLR.IMP    = ifelse(is.na(SOLR),  ifelse(is.na(lag.1.SOLR),  ifelse(is.na(lag.2.SOLR), ifelse(is.na(lag.3.SOLR), ifelse(is.na(lag.4.SOLR), lag.5.SOLR, lag.4.SOLR), lag.3.SOLR),    lag.2.SOLR) ,    lag.1.SOLR ),      SOLR      ))
df5 = mutate(df5, TEMP.IMP    = ifelse(is.na(TEMP),  ifelse(is.na(lag.1.TEMP),  ifelse(is.na(lag.2.TEMP), ifelse(is.na(lag.3.TEMP), ifelse(is.na(lag.4.TEMP), lag.5.TEMP, lag.4.TEMP), lag.3.TEMP),    lag.2.TEMP) ,    lag.1.TEMP ),      TEMP      ))
df5 = mutate(df5, WDIR.IMP    = ifelse(is.na(WDIR),  ifelse(is.na(lag.1.WDIR),  ifelse(is.na(lag.2.WDIR), ifelse(is.na(lag.3.WDIR), ifelse(is.na(lag.4.WDIR), lag.5.WDIR, lag.4.WDIR), lag.3.WDIR),    lag.2.WDIR) ,    lag.1.WDIR ),      WDIR      ))
df5 = mutate(df5, WSPD.IMP    = ifelse(is.na(WSPD),  ifelse(is.na(lag.1.WSPD),  ifelse(is.na(lag.2.WSPD), ifelse(is.na(lag.3.WSPD), ifelse(is.na(lag.4.WSPD), lag.5.WSPD, lag.4.WSPD), lag.3.WSPD),    lag.2.WSPD) ,    lag.1.WSPD ),      WSPD      ))

#df5
dim(df5)


```


# 4c. create difference columns for all variables. Use .IMP variables as the input variables since these are the 'improved' versions. E.g. diff of NO2 since 6AM. 3AM. MIDNIGHT. 
```{r}
# function to create new column in data frame with differenced variables
differenceColumnAdd = function(df, predictor, SinceTimeHoursNum){  
  existColNames = colnames(df)
  
  dfSetHourOfDayValue = df %>% filter(TimeHoursNum==SinceTimeHoursNum) %>% select_('Date', predictor)   # get baseline hour of date - e.g. all NO2 concentrations at 6AM.
  dfNew = inner_join(df,dfSetHourOfDayValue,by = c("Date" = "Date"))                                    # add baseline hour of date as new column 
  
  StaticTimeCol = paste0('TimeHoursNum.',SinceTimeHoursNum,'.',predictor)                               # create baseline hour column name. e.g. TimeHoursNum.6.NO2
  colnames(dfNew) = c(existColNames, StaticTimeCol)
  #colnames(dfNew)[length(dfNew)] = StaticTimeCol                                                        # update column header. i.e. the last column is the new one                                     
  dfSetDiffValue = df[,predictor] - dfNew[,StaticTimeCol]               # calculate diff from e.g. 6AM NO2 baseline to current hour of each day. 
  dfNew = cbind(dfNew,dfSetDiffValue)                                   # add differenced value to column in newly created df
  dfNew = dfNew %>% select(-one_of(StaticTimeCol))                      # drop column with baseline hour of date value since no longer needed in df
  
  new_name = paste0('Diff.',predictor,'.','Base.',SinceTimeHoursNum)
  colnames(dfNew)[length(dfNew)] = new_name                             # rename newly created differenced column to e.g. 'Diff.NO2.Since.6'
  
  return(dfNew)
}

df6 = differenceColumnAdd(df5, 'NO2.IMP', '6')        # note that '6' here is the 6AM time of day. 
df6 = differenceColumnAdd(df6, 'NO.IMP', '6')
df6 = differenceColumnAdd(df6, 'NOX.IMP', '6')
df6 = differenceColumnAdd(df6, 'O3.IMP', '6')
df6 = differenceColumnAdd(df6, 'PM10.IMP', '6')
df6 = differenceColumnAdd(df6, 'SO2.IMP', '6')
df6 = differenceColumnAdd(df6, 'BP.IMP', '6')
df6 = differenceColumnAdd(df6, 'RAIN.IMP', '6')
df6 = differenceColumnAdd(df6, 'RHUM.IMP', '6')
df6 = differenceColumnAdd(df6, 'SOLR.IMP', '6')
df6 = differenceColumnAdd(df6, 'TEMP.IMP', '6')
df6 = differenceColumnAdd(df6, 'WDIR.IMP', '6')
df6 = differenceColumnAdd(df6, 'WSPD.IMP', '6')

# continue on using the function above for diff since 7am.
df6 = differenceColumnAdd(df6, 'NO2.IMP',     '7')        # note that '7' here is the 7AM time of day. 
df6 = differenceColumnAdd(df6, 'NO.IMP',  '7')
df6 = differenceColumnAdd(df6, 'NOX.IMP', '7')
df6 = differenceColumnAdd(df6, 'O3.IMP',  '7')
df6 = differenceColumnAdd(df6, 'PM10.IMP','7')
df6 = differenceColumnAdd(df6, 'SO2.IMP', '7')
df6 = differenceColumnAdd(df6, 'BP.IMP',  '7')
df6 = differenceColumnAdd(df6, 'RAIN.IMP','7')
df6 = differenceColumnAdd(df6, 'RHUM.IMP','7')
df6 = differenceColumnAdd(df6, 'SOLR.IMP','7')
df6 = differenceColumnAdd(df6, 'TEMP.IMP','7')
df6 = differenceColumnAdd(df6, 'WDIR.IMP','7')
df6 = differenceColumnAdd(df6, 'WSPD.IMP','7')

# continue on using the function above for diff since 8am.
df6 = differenceColumnAdd(df6, 'NO2.IMP',      '8')        # note that '8' here is the 8AM time of day. 
df6 = differenceColumnAdd(df6, 'NO.IMP',   '8')
df6 = differenceColumnAdd(df6, 'NOX.IMP',  '8')
df6 = differenceColumnAdd(df6, 'O3.IMP',   '8')
df6 = differenceColumnAdd(df6, 'PM10.IMP', '8')
df6 = differenceColumnAdd(df6, 'SO2.IMP',  '8')
df6 = differenceColumnAdd(df6, 'BP.IMP',   '8')
df6 = differenceColumnAdd(df6, 'RAIN.IMP', '8')
df6 = differenceColumnAdd(df6, 'RHUM.IMP', '8')
df6 = differenceColumnAdd(df6, 'SOLR.IMP', '8')
df6 = differenceColumnAdd(df6, 'TEMP.IMP', '8')
df6 = differenceColumnAdd(df6, 'WDIR.IMP', '8')
df6 = differenceColumnAdd(df6, 'WSPD.IMP', '8')

names(df6)

```

# 4d. for each date we need to calculate the hour of day where the max occurred.
```{r}
getDiffFromMaxConcentrationByDate = function(df, predictor){
  existColNames = colnames(df)

  dfSetMaxConcentrationByDate = df %>% select_('Date', predictor) %>% group_by(Date) %>% summarise_each(funs(max))
  dfNew = inner_join(df,dfSetMaxConcentrationByDate,by = c("Date" = "Date"))                                    # add baseline hour of date as new column 
  tempColName = paste0('max.',predictor)                                   # rename max field created to this name max.predictor
  colnames(dfNew)[length(dfNew)] = tempColName                             # as above
  colnames(dfNew) = c(existColNames, tempColName)                          # rename all variables in temp data frame to prior values plus new max var created
  
  dfSetDiffToMax = dfNew[,predictor] - dfNew[,tempColName] 
  dfNew = cbind(dfNew,dfSetDiffToMax) 
  dfNew = dfNew %>% select(-one_of(tempColName))
  
  newColName = paste0('diffToMax.',predictor,'.ByDate')
  colnames(dfNew) = c(existColNames, newColName) 
  
  return(dfNew)
}

df7 = getDiffFromMaxConcentrationByDate(df6, 'NO2.IMP'     )        # calculate diff in hourly values from max value for each Date in df
df7 = getDiffFromMaxConcentrationByDate(df7, 'NO.IMP'  )
df7 = getDiffFromMaxConcentrationByDate(df7, 'NOX.IMP' )
df7 = getDiffFromMaxConcentrationByDate(df7, 'O3.IMP'  )
df7 = getDiffFromMaxConcentrationByDate(df7, 'PM10.IMP')
df7 = getDiffFromMaxConcentrationByDate(df7, 'SO2.IMP' )
df7 = getDiffFromMaxConcentrationByDate(df7, 'BP.IMP'  )
df7 = getDiffFromMaxConcentrationByDate(df7, 'RAIN.IMP')
df7 = getDiffFromMaxConcentrationByDate(df7, 'RHUM.IMP')
df7 = getDiffFromMaxConcentrationByDate(df7, 'SOLR.IMP')
df7 = getDiffFromMaxConcentrationByDate(df7, 'TEMP.IMP')
df7 = getDiffFromMaxConcentrationByDate(df7, 'WDIR.IMP')
df7 = getDiffFromMaxConcentrationByDate(df7, 'WSPD.IMP')

names(df7)

```



# 4e. for each date we need to calculate the slope between 5-8am 
```{r}
getSlopeFromXamToYamByDate = function(df, predictor, startTime, endTime){
  existColNames = colnames(df)
  dfSet5AMConcentrationByDate = df %>% filter(TimeHoursNum==startTime) %>% select_('Date', predictor) 
  dfSet8AMConcentrationByDate = df %>% filter(TimeHoursNum==endTime) %>% select_('Date', predictor)
  dfTemp = inner_join(dfSet5AMConcentrationByDate, dfSet8AMConcentrationByDate, by = c("Date" = "Date"))
  tempColName1 = paste0('TimeHoursNum.',startTime,'.',predictor)                                                    
  tempColName2 = paste0('TimeHoursNum.',endTime,'.',predictor)                                   
  colnames(dfTemp) = c('Date',tempColName1, tempColName2)
  
  tempColName3 = paste0(startTime,'amTo',endTime,'amSlope.',predictor) 
  slopeDivisor = endTime - startTime
  slopeColName = (dfTemp[,tempColName2] - dfTemp[,tempColName1])/slopeDivisor     # 8am concentration minus 5am concentration /3 (since 3 hours imbetween)
  dfTemp = cbind(dfTemp, slopeColName)
  colnames(dfTemp) = c('Date',tempColName1, tempColName2, tempColName3)
  dfTemp = dfTemp[,c(1,4)]  # i.e. the Date column and the new slope column, only!
  
  # to this point you have Date, e.g. slope 5am to 8am NO2 stored into dfTemp
  dfNew = inner_join(df,dfTemp,by = c("Date" = "Date"))   
  return(dfNew)
  
}

df8 = getSlopeFromXamToYamByDate(df7, 'NO2.IMP'     , 5, 8)   # takes 5 am to 8am slope
df8 = getSlopeFromXamToYamByDate(df8, 'NO.IMP'  , 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'NOX.IMP' , 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'O3.IMP'  , 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'PM10.IMP', 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'SO2.IMP' , 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'BP.IMP'  , 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'RAIN.IMP', 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'RHUM.IMP', 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'SOLR.IMP', 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'TEMP.IMP', 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'WDIR.IMP', 5, 8)
df8 = getSlopeFromXamToYamByDate(df8, 'WSPD.IMP', 5, 8)


df8 = getSlopeFromXamToYamByDate(df8, 'NO2.IMP'  , 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'NO.IMP'  , 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'NOX.IMP' , 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'O3.IMP'  , 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'PM10.IMP', 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'SO2.IMP' , 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'BP.IMP'  , 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'RAIN.IMP', 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'RHUM.IMP', 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'SOLR.IMP', 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'TEMP.IMP', 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'WDIR.IMP', 2, 5)
df8 = getSlopeFromXamToYamByDate(df8, 'WSPD.IMP', 2, 5)




names(df8)
dim(df8)
```


# 4f - for each month we calculate the mean concentrations. then we calc the diff in the value from the mean. 
```{r}
df9 = na.omit(df8)                                                                   # remove the NAs since only care about rows which have all observations. 
dates.over.x.hours = df9 %>% group_by(Date) %>% summarise(n=n()) %>% filter(n==24)   # remove any dates that have less than 24 hours of observations. 
dates.over.x.hours = dates.over.x.hours[,1]                                          
dates.over.x.hours                                                                   # 237 dates with 24 hours of observations

# 6208  409 (for >=18 hour days = 75% or more of hours in day present)             ==> 5688 obs for 24 hours in a day. 5688 / 24 = 237 days (matches above..! good.)
df10 = inner_join(df9, dates.over.x.hours, by = c("Date" = "Date"))
dim(df10)  

months.over.x.days = df10 %>% group_by(MMYYYY) %>% summarise(n=round(n()/24)) %>% filter(n>=10)   # of the dates that have 24 hours of obs 11 months exist between 2008-2016
months.over.x.days = months.over.x.days[,1]                                                       # that have >= 10 dates present
months.over.x.days                                                                                

# let's create a function that can calculate the mean concentration level for each and add that to the df10 data.frame.
df11 = inner_join(df10, months.over.x.days, by = c("MMYYYY","MMYYYY"))
dim(df11)                                                                                         # 185 dates in total which is 4440 observations in total

calculateMonthlyAverage = function(df, predictor) {
  existColNames = colnames(df)
  datesWithMeansDf = df %>% select_('MMYYYY', predictor) %>% group_by_('MMYYYY') %>% summarise_each(funs(mean))
  datesWithMeansDfColName = paste0('Mean.Monthly.',predictor)                                                    
  colnames(datesWithMeansDf) = c('MMYYYY',datesWithMeansDfColName)
  dfNew = inner_join(df, datesWithMeansDf, by = c("MMYYYY" = "MMYYYY"))
  return(dfNew)
}

df12 = calculateMonthlyAverage(df11, 'NO2.IMP')
df12 = calculateMonthlyAverage(df12, 'NO.IMP')
df12 = calculateMonthlyAverage(df12, 'NOX.IMP')
df12 = calculateMonthlyAverage(df12, 'O3.IMP')
df12 = calculateMonthlyAverage(df12, 'PM10.IMP')
df12 = calculateMonthlyAverage(df12, 'SO2.IMP')
df12 = calculateMonthlyAverage(df12, 'BP.IMP')
df12 = calculateMonthlyAverage(df12, 'RAIN.IMP')
df12 = calculateMonthlyAverage(df12, 'RHUM.IMP')
df12 = calculateMonthlyAverage(df12, 'SOLR.IMP')
df12 = calculateMonthlyAverage(df12, 'TEMP.IMP')
df12 = calculateMonthlyAverage(df12, 'WDIR.IMP')
df12 = calculateMonthlyAverage(df12, 'WSPD.IMP')


```

# 4g. for each hours obs we need to calculate the diff from the mean concentration for each month
```{r}
getDiffFromMeanMonthlyConcentration = function(df, predictor){
  existColNames = colnames(df)
  tempColName = paste0('Mean.Monthly.',predictor)
  
  dfSetDiffToMean = df[,predictor] - df[,tempColName]
  dfNew = cbind(df,dfSetDiffToMean) 
  #dfNew = dfNew %>% select(-one_of(tempColName))
  
  newColName = paste0('diffToMean.Monthly.',predictor)
  colnames(dfNew) = c(existColNames, newColName) 
  
  return(dfNew)
}

df13 = getDiffFromMeanMonthlyConcentration(df12, 'NO2.IMP'     ) # calculate diff in hourly values from max value for each Date in df
df13 = getDiffFromMeanMonthlyConcentration(df13, 'NO.IMP'  )
df13 = getDiffFromMeanMonthlyConcentration(df13, 'NOX.IMP' )
df13 = getDiffFromMeanMonthlyConcentration(df13, 'O3.IMP'  )
df13 = getDiffFromMeanMonthlyConcentration(df13, 'PM10.IMP')
df13 = getDiffFromMeanMonthlyConcentration(df13, 'SO2.IMP' )
df13 = getDiffFromMeanMonthlyConcentration(df13, 'BP.IMP'  )
df13 = getDiffFromMeanMonthlyConcentration(df13, 'RAIN.IMP')
df13 = getDiffFromMeanMonthlyConcentration(df13, 'RHUM.IMP')
df13 = getDiffFromMeanMonthlyConcentration(df13, 'SOLR.IMP')
df13 = getDiffFromMeanMonthlyConcentration(df13, 'TEMP.IMP')
df13 = getDiffFromMeanMonthlyConcentration(df13, 'WDIR.IMP')
df13 = getDiffFromMeanMonthlyConcentration(df13, 'WSPD.IMP')

names(df13)
head(df13)

df14 = df13 %>% filter(TimeHoursNum>=6 & TimeHoursNum<=16 & !(Day=='Saturday') & !(Day=='Sunday'))
dim(df14)  # 1936 x 209

```



# 4h - for each month we calculate the mean concentrations by hour of day. 
```{r}
calculateMonthlyHourlyAverage = function(df, predictor) {
  existColNames = colnames(df)
  meanHourlyConcentrationByMonthHourDf = df %>% select_('MMYYYY', 'TimeHoursNum', predictor)  %>% group_by_('MMYYYY','TimeHoursNum') %>% summarise_each(funs(mean))
  meanHourlyConcentrationByMonthHourDfColName = paste0('Mean.Hourly.Concentration.By.MMYYYY.',predictor)                                                    
  colnames(meanHourlyConcentrationByMonthHourDf) = c('MMYYYY','TimeHoursNum',meanHourlyConcentrationByMonthHourDfColName)
  
  dfNew = inner_join(df, meanHourlyConcentrationByMonthHourDf, by = c("MMYYYY" = "MMYYYY", "TimeHoursNum" = "TimeHoursNum"))
  return(dfNew)
}

# calculateMonthlyHourlyAverage(temp, 'b')

df15 = calculateMonthlyHourlyAverage(df14, 'NO2.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'NO.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'NOX.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'O3.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'PM10.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'SO2.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'BP.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'RAIN.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'RHUM.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'SOLR.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'TEMP.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'WDIR.IMP')
df15 = calculateMonthlyHourlyAverage(df15, 'WSPD.IMP')


```

# 5a - for each date calculate the prior dates min/max values 0-8 AM 

```{r}
calculateAM.Max = function(df, predictor) {
  # calc max 0-8AM
  dfNew = df %>% select_('Date','TimeHoursNum',predictor) %>% filter(TimeHoursNum>=6 & TimeHoursNum <=  8) %>% group_by_('Date') %>% summarise_each(funs(max))
  dfNew = dfNew %>% select_('Date',predictor)
  maxColname = paste0('max.6.to.8.AM.',predictor)
  colnames(dfNew) = c('Date',maxColname)
  dfNew = inner_join(df, dfNew, by = c("Date" = "Date"))
  
  #repeat for min 0-8AM
  dfNew2 = dfNew %>% select_('Date','TimeHoursNum',predictor) %>% filter(TimeHoursNum>=6 & TimeHoursNum <=  8) %>% group_by_('Date') %>% summarise_each(funs(min))
  dfNew2 = dfNew2 %>% select_('Date',predictor)
  minColname = paste0('min.6.to.8.AM.',predictor)
  colnames(dfNew2) = c('Date',minColname)
  dfNew2 = inner_join(dfNew, dfNew2, by = c("Date" = "Date"))
  
  return(dfNew2)
}

df16 = calculateAM.Max(df15, 'NO2.IMP')
df16 = calculateAM.Max(df16, 'NO.IMP')
df16 = calculateAM.Max(df16, 'NOX.IMP')
df16 = calculateAM.Max(df16, 'O3.IMP')
df16 = calculateAM.Max(df16, 'PM10.IMP')
df16 = calculateAM.Max(df16, 'SO2.IMP')
df16 = calculateAM.Max(df16, 'BP.IMP')
df16 = calculateAM.Max(df16, 'RAIN.IMP')
df16 = calculateAM.Max(df16, 'RHUM.IMP')
df16 = calculateAM.Max(df16, 'SOLR.IMP')
df16 = calculateAM.Max(df16, 'TEMP.IMP')
df16 = calculateAM.Max(df16, 'WDIR.IMP')
df16 = calculateAM.Max(df16, 'WSPD.IMP')

```

```{r}
df16 = df16 %>% select(Date, Time, MMYYYY:TimeHoursNum,                  # date Time variables
                    NO:WSPD,                                          # current hour response (actual) variables (include imputed values from other stations)
                    lag.1.NO:lag.5.WSPD,                              # lagged meteorological and pollutant variables
                    NO.IMP:WSPD.IMP,                                  # current hour imputed variables
                    Mean.Monthly.NO2.IMP:Mean.Monthly.WSPD.IMP,       # mean monthly concentration levels
                    Mean.Hourly.Concentration.By.MMYYYY.NO2.IMP: Mean.Hourly.Concentration.By.MMYYYY.WSPD.IMP,   # mean hourly concentration levels (by month)
                    `5amTo8amSlope.NO2.IMP`:`2amTo5amSlope.WSPD.IMP`,
                    max.6.to.8.AM.NO2.IMP:min.6.to.8.AM.WSPD.IMP)             # max AM pollutant concentration and max AM meteo vals 

outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED")
write.csv(df16, file.path(outfilePath,'greenwich_eltham_imputed_school_hours_take2.csv'))
dim(df16)  # 1936 x 183
```



<!-- Figure out which variables it makes sense to take the lagged t-1, t-2, and t-3 values. For correlations we need to remove the NA values first. This is slightly misleading since the NA values between two dates that are far apart may be problematic. May need to revert back to this, but we are trying here to get a sense of the correlation so i continue with the na.omit method for now. Alt: use count hourly obs that have the longest possible count of consec hours. -->

<!-- NO.cor    = cor(df5 %>% select(NO,lag.1.NO,lag.2.NO,lag.3.NO, lag.4.NO, lag.5.NO))[1,] -->
<!-- NO2.cor   = cor(df5 %>% select(NO2,lag.1.NO2,lag.2.NO2,lag.3.NO2, lag.4.NO2, lag.5.NO2))[1,] -->
<!-- NOX.cor   = cor(df5 %>% select(NOX,lag.1.NOX,lag.2.NOX,lag.3.NOX, lag.4.NOX, lag.5.NOX))[1,] -->
<!-- O3.cor    = cor(df5 %>% select(O3,lag.1.O3,lag.2.O3,lag.3.O3, lag.4.O3, lag.5.O3))[1,] -->
<!-- PM10.cor  = cor(df5 %>% select(PM10,lag.1.PM10,lag.2.PM10,lag.3.PM10, lag.4.PM10, lag.5.PM10))[1,] -->
<!-- PM2.5.cor = cor(df5 %>% select(PM2.5,lag.1.PM2.5,lag.2.PM2.5,lag.3.PM2.5, lag.4.PM2.5, lag.5.PM2.5))[1,] -->
<!-- SO2.cor   = cor(df5 %>% select(SO2,lag.1.SO2,lag.2.SO2,lag.3.SO2, lag.4.SO2, lag.5.SO2))[1,] -->
<!-- BP.cor    = cor(df5 %>% select(BP,lag.1.BP,lag.2.BP,lag.3.BP, lag.4.BP, lag.5.BP))[1,] -->
<!-- RAIN.cor  = cor(df5 %>% select(RAIN,lag.1.RAIN,lag.2.RAIN,lag.3.RAIN, lag.4.RAIN, lag.5.RAIN))[1,] # not correlated at all!! -> best can do it take 0... the modal value. -->
<!-- RHUM.cor  = cor(df5 %>% select(RHUM,lag.1.RHUM,lag.2.RHUM,lag.3.RHUM, lag.4.RHUM, lag.5.RHUM))[1,] -->
<!-- SOLR.cor  = cor(df5 %>% select(SOLR,lag.1.SOLR,lag.2.SOLR,lag.3.SOLR, lag.4.SOLR, lag.5.SOLR))[1,] -->
<!-- TEMP.cor  = cor(df5 %>% select(TEMP,lag.1.TEMP,lag.2.TEMP,lag.3.TEMP, lag.4.TEMP, lag.5.TEMP))[1,] -->
<!-- WDIR.cor  = cor(df5 %>% select(WDIR,lag.1.WDIR,lag.2.WDIR,lag.3.WDIR, lag.4.WDIR, lag.5.WDIR))[1,] -->
<!-- WSPD.cor  = cor(df5 %>% select(WSPD,lag.1.WSPD,lag.2.WSPD,lag.3.WSPD, lag.4.WSPD, lag.5.WSPD))[1,] -->

