```{r}
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }

# Next, we download packages that H2O depends on.
if (! ("methods" %in% rownames(installed.packages()))) { install.packages("methods") }
if (! ("statmod" %in% rownames(installed.packages()))) { install.packages("statmod") }
if (! ("stats" %in% rownames(installed.packages()))) { install.packages("stats") }
if (! ("graphics" %in% rownames(installed.packages()))) { install.packages("graphics") }
if (! ("RCurl" %in% rownames(installed.packages()))) { install.packages("RCurl") }
if (! ("jsonlite" %in% rownames(installed.packages()))) { install.packages("jsonlite") }
if (! ("tools" %in% rownames(installed.packages()))) { install.packages("tools") }
if (! ("utils" %in% rownames(installed.packages()))) { install.packages("utils") }

# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-tverberg/5/R")))
library(h2o)
localH2O = h2o.init(nthreads=-1)
```



```{r}
#install.packages("beepr")
library(beepr)
library(dplyr)
library(lubridate)
codePath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","R CODE")
source(file.path(codePath,"thesis_data_preparation_part3_take2.R"))

modelPath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","MODELS") 
inPath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

nodeCount = c(9) #ceiling(colcount/2),5,10)
response        = c('NO2') 

for (nodeNum in 1:length(nodeCount)){
# get data set fields that I can use in the model. 
df.temp.predictors = df %>% select(MMYYYY, Year, Month, Week, Day, TimeHoursNum, BP:WSPD, lag.1.NO:lag.5.WSPD, X5amTo8amSlope.NO2.IMP:min.6.to.8.AM.WSPD.IMP )
includeIdx            = which(names(df) %in% c(response))
dfResponse            = df[,includeIdx]
df = cbind(dfResponse, df.temp.predictors)
colnames(df)[1] = response
df

# Prep the testing data using 70-20-10 split. End up taking 12.5% for the validation set. This is data that is collected after Jan 2014. 
validationDf    = df %>% filter(Year >= 2014)    # First -- set aside the validation data - i.e. dates/hours after jan 2014
nonValidationDf = df %>% filter(Year  < 2014)  # Second -- divide the remaining df between training and testing using an 80-20 split

# split out the non validation data frame into training and test data
df = nonValidationDf









createDataFrame = function(df,responseCol,params){
  dfParamsInclude   = which(names(df) %in% c(params))
  dfNewParams       = df[,dfParamsInclude]
  dfNewResponseInc  = which(names(df) %in% c(responseCol))
  dfNewResponse     = df[,dfNewResponseInc]
  dfNew             = cbind(dfNewResponse, dfNewParams)
  colnames(dfNew)[1] = paste0(responseCol)
  return(dfNew)
}

chosenVar        = c()
mae.train.latest = c()
mae.test.latest  = c()
mae.xval.latest  = c()

for (i in 1:6){

##response        = c('O3')    # NO, NOX, SO2, PM10, PM2.5  Done: NO2 (0.5, 5, 10)
results         = c()

# get data set fields that I can use in the model. 
dropIdx               = which(names(df) %in% c('Year', 'MMYYYY', response, chosenVar)) #chosenVar[length(chosenVar)])) #chosenVar))
dfPredictors          = df[,-dropIdx]
predictorVariableList = names(dfPredictors)


# get all values in data frame that are remaining and find all combinations of each --> i changed this to be '1' var added each time so combination no longer needed, but i keep for future ref and change the combination to '1' var.
combn = data.frame(combn(predictorVariableList, 1))

set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

  if(length(mae.xval.latest)>1){
    if(mae.xval.latest[length(mae.xval.latest)] > mae.xval.latest[length(mae.xval.latest)-1]) {
      break
    }
  }
  
  for (i in 1:1){

    for (j in 1:dim(combn)[2]){  
      
    # create the data frame
    #paramList = as.list(t(combn[j]))    # for this next loop we need to add chosenVar's + 1 from each combn
    #listVars  = chosenVar[length(chosenVar)]
    paramList = append(chosenVar, as.list(t(combn[j])))
    dfNew = createDataFrame(df, response[i], paramList)
     
    # # rename the df to df.train, df.test, and df.vali respectively
    df.train = dfNew[train,]
    df.test  = dfNew[-train,]
    # 
    # # create h2o-ready frame
    df.train.hex <- as.h2o(df.train)
    df.test.hex <- as.h2o(df.test)
     
    # check on colcount
    if(j == 1){
      colcount = 2
    } else {
      colcount = dim(df.train.hex)[2]  
      }
    
    #nodes_layer1 = ceiling(colcount/2)   # 1
    #nodes_layer1 = 5
    #nodes_layer1 = 10
    nodes_layer1 = nodeCount[nodeNum]
    df.train.dl <- h2o.deeplearning(x = 2:colcount, y = 1, training_frame = df.train.hex, validation_frame= df.test.hex, hidden=c(nodes_layer1), 
                                   distribution= "AUTO", variable_importances = TRUE, reproducible = TRUE, seed = 1234, nfolds=10) 
  
    mae.train = h2o.mae(df.train.dl, train = TRUE,  valid = FALSE, xval=FALSE)
    mae.test  = h2o.mae(df.train.dl, train = FALSE, valid = TRUE,  xval=FALSE)
    mae.xval  = h2o.mae(df.train.dl, train = FALSE, valid = FALSE, xval=TRUE)
  
    # next: create the results table which will be a csv file with response, inputVariableName(s), mae train, test, and vali as other columns
    responseCol = response[i]
    inputVarCol = as.character(t(paramList))
  
    results.temp = data.frame(responseCol, j, inputVarCol, mae.train, mae.test, mae.xval)  #
    results = rbind(results, results.temp)
  
  
    }

  
  }

# note - had to re-do results since the adding of results to the last results table doesnt work for the 'toString' section.
#results = results[129:382,]
x = results %>%
  group_by(responseCol, j) %>%
  summarise(predictorVar = toString(inputVarCol)) %>%
  ungroup()

# next: i need to join back to the 'j' col the output for the mae.train, mae.test, and mae.vali
y = inner_join(x, results, by=("j" = "j"))
y = y %>% group_by(j) %>% filter(row_number(mae.train) == 1)
y = y %>% select(j, responseCol.x, predictorVar, mae.train, mae.test, mae.xval)
y = y[,-1]  # remove the 'j'!!

# at this point we have a table of values that we can use, but need to select the one var that minimizes the mae.xval
y = y %>% select(responseCol.x, predictorVar, mae.train, mae.test, mae.xval) %>% slice(which.min(mae.xval))

# variable 1 selected for predicting NO2 is lag.1.NO2. No surprises there. The mae.xval is 4.544425 
# variable 2 selected for predicting NO2 is the lag.1.SOLR.                The mae.xval is 4.360116
# variable 3 selected for predicting NO2 is the lag.2.NO2.                 The mae.xval is 4.259163
addPredictorVar = unlist(strsplit(y$predictorVar, split=", "))
chosenVar       = append(chosenVar, addPredictorVar[length(addPredictorVar)]) #y$predictorVar)
mae.train.latest = append(mae.train.latest,min(y$mae.train))
mae.test.latest = append(mae.test.latest,min(y$mae.test))
mae.xval.latest = append(mae.xval.latest,min(y$mae.xval))


}

# chosenVar
# mae.train.latest
# mae.test.latest
# mae.xval.latest
# nodeCount[nodeNum]









#EXPORT THE MODEL MAE RESULTS TO A CSV
# remove the last value as that has the higher MAE

# 
if (length(chosenVar)==2) {
  chosenVar.final        = chosenVar
  mae.train.latest.final = mae.train.latest
  mae.test.latest.final  = mae.test.latest
  mae.xval.latest.final  = mae.xval.latest
  } else {
  chosenVar.final        = chosenVar[1:length(chosenVar)-1]
  mae.train.latest.final = mae.train.latest[1:length(mae.train.latest)-1]
  mae.test.latest.final  = mae.test.latest[1:length(mae.test.latest)-1]
  mae.xval.latest.final  = mae.xval.latest[1:length(mae.xval.latest)-1]
}

# # Export the data prediction for the testing and validation data sets
outfilePath = file.path("~/Dropbox","NU","THESIS_MAC","thesis","DATASETS","RESULTS", "PREDICTIONS","FORWARD_VAR_PREDICTIONS")
dfExportResults = data.frame(chosenVar.final, mae.train.latest.final, mae.test.latest.final, mae.xval.latest.final, 1)
#dfExportResults

# get min mae.xval predictor inputs
dfExportResults2 = dfExportResults %>%
  group_by(X1) %>%
  summarise(chosenVar.final = toString(chosenVar.final)) %>%
  ungroup()

dfExportResults2 = inner_join(dfExportResults, dfExportResults2, by=("X1" = "X1"))
colnames(dfExportResults2)[length(dfExportResults2)] = 'chosenVar.final'
dfExport = dfExportResults2 %>% select(chosenVar.final, mae.train.latest.final, mae.test.latest.final, mae.xval.latest.final) %>% slice(which.min(mae.xval.latest.final))
dfExport$nodes = as.factor(nodeCount[nodeNum]) #'ceiling(input var count *0.5)')   #,10,5)
dfExport$response = response[1]  # should be O3 now..  #c('NOX') #, 'NO', 'NO')
dfExport$X = 10 # increase +1 each time
dfExport = dfExport %>% select(X, chosenVar.final, mae.test.latest.final, mae.train.latest.final, mae.xval.latest.final, nodes, response)
# dfExport


dfPrior  = read.csv(file.path(outfilePath,"dfExportResultsNO2.csv"),na.strings=c("NA"," "))
dfPrior = dfPrior[2:length(dfPrior)]
colnames(dfExport) = colnames(dfPrior)
dfNew    = rbind(dfPrior, dfExport)
#dfNew

# names(dfExport)
# names(dfPrior)
#ID = dfExport$X + 1


write.csv(dfNew, file.path(outfilePath,'dfExportResultsNO2.csv'))    # # NO2, NO, NOX, O3, PM10, PM2.5, SO2

} 

beep()


```



