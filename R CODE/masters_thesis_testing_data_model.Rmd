```{r}
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }

# Next, we download packages that H2O depends on.
if (! ("methods" %in% rownames(installed.packages()))) { install.packages("methods") }
if (! ("statmod" %in% rownames(installed.packages()))) { install.packages("statmod") }
if (! ("stats" %in% rownames(installed.packages()))) { install.packages("stats") }
if (! ("graphics" %in% rownames(installed.packages()))) { install.packages("graphics") }
if (! ("RCurl" %in% rownames(installed.packages()))) { install.packages("RCurl") }
if (! ("jsonlite" %in% rownames(installed.packages()))) { install.packages("jsonlite") }
if (! ("tools" %in% rownames(installed.packages()))) { install.packages("tools") }
if (! ("utils" %in% rownames(installed.packages()))) { install.packages("utils") }

# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-tverberg/5/R")))
library(h2o)
localH2O = h2o.init(nthreads=-1)
```

9AM prediction 

```{r}
library(dplyr)
library(lubridate)
codePath = file.path("~/Dropbox","NU","THESIS","R CODE")
source(file.path(codePath,"thesis_data_preparation_part3_take2.R"))

modelPath = file.path("~/Dropbox","NU","THESIS","MODELS") 
inPath = file.path("~/Dropbox","NU","THESIS","DATASETS","GROOMED") # Home path
df = read.csv(file.path(inPath,"greenwich_eltham_imputed_school_hours_take2.csv"),na.strings=c("NA"," "))

response          = c('NO2')                           #, 'NO', 'NOX', 'O3', 'PM10', 'PM2.5', 'SO2') 
#inputVariableList = c('NO','NO2','NOX','O3','PM10')


createDataFrame = function(df,responseCol,params){
  dfParamsInclude   = which(names(df) %in% c(params))
  dfNewParams       = df[,dfParamsInclude]
  dfNewResponseInc  = which(names(df) %in% c(responseCol))
  dfNewResponse     = df[,dfNewResponseInc]
  dfNew             = cbind(dfNewResponse, dfNewParams)
  colnames(dfNew)[1] = paste0(responseCol)
  return(dfNew)
}

#createDataFrame(df, 'NO2', c('NO','NOX','O3'))

combn = data.frame(combn(c('NO','NOX','O3','PM10','PM2.5','SO2','BP','RAIN','RHUM','SOLR','TEMP','WDIR','WSPD'), 2))
#combn

#   [1] "X"                                            "Date"                                         "Time"                                        
#   [4] "MMYYYY"                                       "Year"                                         "Month"                                       
#   [7] "Week"                                         "Day"                                          "TimeHoursNum"                                
#  [10] "NO"                                           "NO2"                                          "NOX"                                         
#  [13] "O3"                                           "PM10"                                         "PM2.5"                                       
#  [16] "SO2"                                          "BP"                                           "RAIN"                                        
#  [19] "RHUM"                                         "SOLR"                                         "TEMP"                                        
#  [22] "WDIR"                                         "WSPD"                                         "lag.1.NO"                                    
#  [25] "lag.2.NO"                                     "lag.3.NO"                                     "lag.4.NO"                                    
#  [28] "lag.5.NO"                                     "lag.1.NO2"                                    "lag.2.NO2"                                   
#  [31] "lag.3.NO2"                                    "lag.4.NO2"                                    "lag.5.NO2"                                   
#  [34] "lag.1.NOX"                                    "lag.2.NOX"                                    "lag.3.NOX"                                   
#  [37] "lag.4.NOX"                                    "lag.5.NOX"                                    "lag.1.O3"                                    
#  [40] "lag.2.O3"                                     "lag.3.O3"                                     "lag.4.O3"                                    
#  [43] "lag.5.O3"                                     "lag.1.PM10"                                   "lag.2.PM10"                                  
#  [46] "lag.3.PM10"                                   "lag.4.PM10"                                   "lag.5.PM10"                                  
#  [49] "lag.1.PM2.5"                                  "lag.2.PM2.5"                                  "lag.3.PM2.5"                                 
#  [52] "lag.4.PM2.5"                                  "lag.5.PM2.5"                                  "lag.1.SO2"                                   
#  [55] "lag.2.SO2"                                    "lag.3.SO2"                                    "lag.4.SO2"                                   
#  [58] "lag.5.SO2"                                    "lag.1.BP"                                     "lag.2.BP"                                    
#  [61] "lag.3.BP"                                     "lag.4.BP"                                     "lag.5.BP"                                    
#  [64] "lag.1.RAIN"                                   "lag.2.RAIN"                                   "lag.3.RAIN"                                  
#  [67] "lag.4.RAIN"                                   "lag.5.RAIN"                                   "lag.1.RHUM"                                  
#  [70] "lag.2.RHUM"                                   "lag.3.RHUM"                                   "lag.4.RHUM"                                  
#  [73] "lag.5.RHUM"                                   "lag.1.SOLR"                                   "lag.2.SOLR"                                  
#  [76] "lag.3.SOLR"                                   "lag.4.SOLR"                                   "lag.5.SOLR"                                  
#  [79] "lag.1.TEMP"                                   "lag.2.TEMP"                                   "lag.3.TEMP"                                  
#  [82] "lag.4.TEMP"                                   "lag.5.TEMP"                                   "lag.1.WDIR"                                  
#  [85] "lag.2.WDIR"                                   "lag.3.WDIR"                                   "lag.4.WDIR"                                  
#  [88] "lag.5.WDIR"                                   "lag.1.WSPD"                                   "lag.2.WSPD"                                  
#  [91] "lag.3.WSPD"                                   "lag.4.WSPD"                                   "lag.5.WSPD"                                  
#  [94] "NO.IMP"                                       "NO2.IMP"                                      "NOX.IMP"                                     
#  [97] "O3.IMP"                                       "PM10.IMP"                                     "SO2.IMP"                                     
# [100] "BP.IMP"                                       "RAIN.IMP"                                     "RHUM.IMP"                                    
# [103] "SOLR.IMP"                                     "TEMP.IMP"                                     "WDIR.IMP"                                    
# [106] "WSPD.IMP"                                     "Mean.Monthly.NO2.IMP"                         "Mean.Monthly.NO.IMP"                         
# [109] "Mean.Monthly.NOX.IMP"                         "Mean.Monthly.O3.IMP"                          "Mean.Monthly.PM10.IMP"                       
# [112] "Mean.Monthly.SO2.IMP"                         "Mean.Monthly.BP.IMP"                          "Mean.Monthly.RAIN.IMP"                       
# [115] "Mean.Monthly.RHUM.IMP"                        "Mean.Monthly.SOLR.IMP"                        "Mean.Monthly.TEMP.IMP"                       
# [118] "Mean.Monthly.WDIR.IMP"                        "Mean.Monthly.WSPD.IMP"                        "Mean.Hourly.Concentration.By.MMYYYY.NO2.IMP" 
# [121] "Mean.Hourly.Concentration.By.MMYYYY.NO.IMP"   "Mean.Hourly.Concentration.By.MMYYYY.NOX.IMP"  "Mean.Hourly.Concentration.By.MMYYYY.O3.IMP"  
# [124] "Mean.Hourly.Concentration.By.MMYYYY.PM10.IMP" "Mean.Hourly.Concentration.By.MMYYYY.SO2.IMP"  "Mean.Hourly.Concentration.By.MMYYYY.BP.IMP"  
# [127] "Mean.Hourly.Concentration.By.MMYYYY.RAIN.IMP" "Mean.Hourly.Concentration.By.MMYYYY.RHUM.IMP" "Mean.Hourly.Concentration.By.MMYYYY.SOLR.IMP"
# [130] "Mean.Hourly.Concentration.By.MMYYYY.TEMP.IMP" "Mean.Hourly.Concentration.By.MMYYYY.WDIR.IMP" "Mean.Hourly.Concentration.By.MMYYYY.WSPD.IMP"
# [133] "X5amTo8amSlope.NO2.IMP"                       "X5amTo8amSlope.NO.IMP"                        "X5amTo8amSlope.NOX.IMP"                      
# [136] "X5amTo8amSlope.O3.IMP"                        "X5amTo8amSlope.PM10.IMP"                      "X5amTo8amSlope.SO2.IMP"                      
# [139] "X5amTo8amSlope.BP.IMP"                        "X5amTo8amSlope.RAIN.IMP"                      "X5amTo8amSlope.RHUM.IMP"                     
# [142] "X5amTo8amSlope.SOLR.IMP"                      "X5amTo8amSlope.TEMP.IMP"                      "X5amTo8amSlope.WDIR.IMP"                     
# [145] "X5amTo8amSlope.WSPD.IMP"                      "X2amTo5amSlope.NO2.IMP"                       "X2amTo5amSlope.NO.IMP"                       
# [148] "X2amTo5amSlope.NOX.IMP"                       "X2amTo5amSlope.O3.IMP"                        "X2amTo5amSlope.PM10.IMP"                     
# [151] "X2amTo5amSlope.SO2.IMP"                       "X2amTo5amSlope.BP.IMP"                        "X2amTo5amSlope.RAIN.IMP"                     
# [154] "X2amTo5amSlope.RHUM.IMP"                      "X2amTo5amSlope.SOLR.IMP"                      "X2amTo5amSlope.TEMP.IMP"                     
# [157] "X2amTo5amSlope.WDIR.IMP"                      "X2amTo5amSlope.WSPD.IMP"                      "max.6.to.8.AM.NO2.IMP"                       
# [160] "min.6.to.8.AM.NO2.IMP"                        "max.6.to.8.AM.NO.IMP"                         "min.6.to.8.AM.NO.IMP"                        
# [163] "max.6.to.8.AM.NOX.IMP"                        "min.6.to.8.AM.NOX.IMP"                        "max.6.to.8.AM.O3.IMP"                        
# [166] "min.6.to.8.AM.O3.IMP"                         "max.6.to.8.AM.PM10.IMP"                       "min.6.to.8.AM.PM10.IMP"                      
# [169] "max.6.to.8.AM.SO2.IMP"                        "min.6.to.8.AM.SO2.IMP"                        "max.6.to.8.AM.BP.IMP"                        
# [172] "min.6.to.8.AM.BP.IMP"                         "max.6.to.8.AM.RAIN.IMP"                       "min.6.to.8.AM.RAIN.IMP"                      
# [175] "max.6.to.8.AM.RHUM.IMP"                       "min.6.to.8.AM.RHUM.IMP"                       "max.6.to.8.AM.SOLR.IMP"                      
# [178] "min.6.to.8.AM.SOLR.IMP"                       "max.6.to.8.AM.TEMP.IMP"                       "min.6.to.8.AM.TEMP.IMP"                      
# [181] "max.6.to.8.AM.WDIR.IMP"                       "min.6.to.8.AM.WDIR.IMP"                       "max.6.to.8.AM.WSPD.IMP"                      
# [184] "min.6.to.8.AM.WSPD.IMP"                      

# dim(temp)[2]  # is the column count 
# for (i in 1:2){
#   paramList = as.list(t(combn[i]))
#   createDataFrame(df, 'NO2', paramList)
# }


# split out the data 70-30
set.seed(123)
smp.size = floor(0.70 * nrow(df))
train = sample(seq_len(nrow(df)), size = smp.size)
test = -train

results = data.frame()


for (i in 1:1){

  for (j in 1:dim(combn)[2]){  
    
  # create the data frame
  paramList = as.list(t(combn[j]))
  dfNew = createDataFrame(df, response[i], paramList)
   
  # # rename the df to df.train, df.test, and df.vali respectively
  df.train = dfNew[train,]
  df.test  = dfNew[-train,]
  # 
  # # create h2o-ready frame
  df.train.hex <- as.h2o(df.train)
  df.test.hex <- as.h2o(df.test)
  # 

  colcount = dim(df.train.hex)[2]
  df.train.dl <- h2o.deeplearning(x = 2:colcount, y = 1, training_frame = df.train.hex, validation_frame= df.test.hex, hidden=c(10), 
                                 distribution= "AUTO", variable_importances = TRUE, reproducible = TRUE, seed = 1234, nfolds=10) 

  mae.train = h2o.mae(df.train.dl, train = TRUE,  valid = FALSE, xval=FALSE)
  mae.test  = h2o.mae(df.train.dl, train = FALSE, valid = TRUE,  xval=FALSE)
  mae.xval  = h2o.mae(df.train.dl, train = FALSE, valid = FALSE, xval=TRUE)

  # next: create the results table which will be a csv file with response, inputVariableName(s), mae train, test, and vali as other columns
  responseCol = response[i]
  inputVarCol = as.character(t(paramList))

  results.temp = data.frame(responseCol, j, inputVarCol, mae.train, mae.test, mae.xval)  #
  results = rbind(results, results.temp)


  }

  
}

results
combn

x = results %>%
  group_by(responseCol, j) %>%
  summarise(test = toString(inputVarCol)) %>%
  ungroup()
x

# next: i need to join back to the 'j' col the output for the mae.train, mae.test, and mae.vali
y = inner_join(x, results, by=("j" = "j"))
y = y %>% group_by(j) %>% filter(row_number(mae.train) == 1)
y %>% select(responseCol.x, test, mae.train, mae.test, mae.xval)

```





<!-- # Save the model -->
<!-- model_path <- h2o.saveModel(object=df.train.dl, path=modelPath, force=TRUE) -->
<!-- # print(model_path) -->
<!-- # /tmp/mymodel/DeepLearning_model_R_1441838096933 -->

<!-- # make a prediction here for train, test, validation set response -->
<!-- predictions.train <- h2o.predict(df.train.dl, df.train.hex) -->
<!-- predictions.test  <- h2o.predict(df.train.dl, df.test.hex) -->
<!-- predictions.vali  <- h2o.predict(df.train.dl, df.vali.hex) -->

<!-- # Export the data prediction for the testing and validation data sets -->
<!-- outfilePath = file.path("~/Dropbox","NU","THESIS","DATASETS","RESULTS", "PREDICTIONS","ONE_HOUR_AHEAD_PREDICTIONS") -->
<!-- filenameTrain = paste0('greenwich_eltham_',response[i],'_ann_train_1_hr_ahead.csv')   # TWO HOURS AHEAD, THREE HOURS, ETC... WILL BE THE NAMES OF THE NEW FILES -->
<!-- filenameTest  = paste0('greenwich_eltham_',response[i],'_ann_test_1_hr_ahead.csv') -->
<!-- filenameVali  = paste0('greenwich_eltham_',response[i],'_ann_vali_1_hr_ahead.csv') -->

<!-- # EXPORT THE TEST DATA SET PREDICTIONS -->
<!-- dfExportTrain = as.data.frame(h2o.cbind(predictions.train,df.train.hex)) -->
<!-- dfExportTrain = dfExportTrain %>% filter(TimeHoursNum == '9') -->
<!-- dfExportTrain$TimeKey1 = as.POSIXct(dfExportTrain$Time) + hours(1) -->
<!-- dfExportTrain$TimeKey2 = as.POSIXct(dfExportTrain$Time) + hours(2) -->
<!-- dfExportTrain$TimeKey3 = as.POSIXct(dfExportTrain$Time) + hours(3) -->
<!-- dfExportTrain$TimeKey4 = as.POSIXct(dfExportTrain$Time) + hours(4) -->
<!-- dfExportTrain$TimeKey5 = as.POSIXct(dfExportTrain$Time) + hours(5) -->
<!-- keepIdx = which(names(dfExportTrain) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5")) -->
<!-- dfExportTrain = dfExportTrain[,keepIdx] -->
<!-- write.csv(dfExportTrain, file.path(outfilePath,filenameTrain))   # to here: we have exported a training file containing ALL the 9am predictions for ALL pollutant/meteo vars -->

<!-- # EXPORT THE TEST DATA SET PREDICTIONS -->
<!-- dfExportTest = as.data.frame(h2o.cbind(predictions.test,df.test.hex)) -->
<!-- dfExportTest = dfExportTest %>% filter(TimeHoursNum == '9') -->
<!-- dfExportTest$TimeKey1 = as.POSIXct(dfExportTest$Time) + hours(1) -->
<!-- dfExportTest$TimeKey2 = as.POSIXct(dfExportTest$Time) + hours(2) -->
<!-- dfExportTest$TimeKey3 = as.POSIXct(dfExportTest$Time) + hours(3) -->
<!-- dfExportTest$TimeKey4 = as.POSIXct(dfExportTest$Time) + hours(4) -->
<!-- dfExportTest$TimeKey5 = as.POSIXct(dfExportTest$Time) + hours(5) -->
<!-- keepIdx = which(names(dfExportTest) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5")) -->
<!-- dfExportTest = dfExportTest[,keepIdx] -->
<!-- write.csv(dfExportTest, file.path(outfilePath,filenameTest))    # to here: we have exported a testing file containing ALL the 9am predictions for ALL pollutant/meteo vars -->

<!-- # EXPORT THE VALIDATION DATA SET PREDICTIONS -->
<!-- dfExportVali = as.data.frame(h2o.cbind(predictions.vali,df.vali.hex)) -->
<!-- dfExportVali = dfExportVali %>% filter(TimeHoursNum == '9') -->
<!-- dfExportVali$TimeKey1 = as.POSIXct(dfExportVali$Time) + hours(1) -->
<!-- dfExportVali$TimeKey2 = as.POSIXct(dfExportVali$Time) + hours(2) -->
<!-- dfExportVali$TimeKey3 = as.POSIXct(dfExportVali$Time) + hours(3) -->
<!-- dfExportVali$TimeKey4 = as.POSIXct(dfExportVali$Time) + hours(4) -->
<!-- dfExportVali$TimeKey5 = as.POSIXct(dfExportVali$Time) + hours(5) -->
<!-- keepIdx = which(names(dfExportVali) %in% c(response[i], "predict","Time","TimeKey1","TimeKey2","TimeKey3","TimeKey4","TimeKey5")) -->
<!-- dfExportVali = dfExportVali[,keepIdx] -->
<!-- write.csv(dfExportVali, file.path(outfilePath,filenameVali))    # to here: we have exported a validation file containing ALL the 9am predictions for ALL pollutant/meteo vars -->

<!-- # # CALC the MAE here -->
<!-- dfExportTrain.MAE = mean(abs(dfExportTrain$predict - dfExportTrain$NO2)) -->
<!-- #dfExportTrain.MAE # 4.129 / 4.178   => 3.140417 / 3.615189 / 3.251841  = with  5 lags included. -->
<!-- #dfExportTrain.MAE # 4.129 / 4.178   => 3.312458 / 3.056598 / 2.760583 / 3.119739  = with  3 lags included. -->
<!-- dfExportTrain.MAE # 4.129 / 4.178   => 3.367783 / 3.575584 / 3.677053  = with  3 lags included. -->
<!-- # names(df) -->

<!-- }  -->

<!-- summary(df.train.dl) -->
<!-- h2o.varimp(df.train.dl) -->


<!-- ``` -->

